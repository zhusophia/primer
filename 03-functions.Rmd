# Functions {#functions}

<!-- The functions created here should be more tightly connected to the functions created in the tutorial. Recall that we will be merging the tutorial into the chapter this summer, I hope! -->

<!-- And we also want to lay the groundwork for the problem set (and exam) which require writing a function. And, finally, all these exercises should be teaching something which is then referenced in probability and in stan_glm. Yet it is not clear what those would be. Maybe some simulations? -->

<!-- If the Democrats have a 50% chance of winning each seat in the Senate, what are the odds of them getting 60 seats (to beat the filibuster) at any one time? How much does their advantage have to be to have a 20% chance of getting 60? Do this first while pretending that all senates run each two years. Then do it staggered. Or is all that too complex? -->

<!-- Maybe an advanced form of the guessing game in which we are allowed to provide a function. The goal of inference is to come up with a function which wins the prediction game. -->

<!-- This is currently in problem set #3: Change the objective function. The simplest form of the Guessing Game just counts each contest separately. A more advanced for would give you a penalty which varies depending on how wrong you are. (This, obviously, is one way to think about minimizing the squared residuals.) This is very fun because there are many different penalty functions, each of which may lead to a different function winning the Guessing Game. -->

<!-- Another form of the Guessing Game is like a casino. One person (the Casino) gives a 50% confidence interval. The other person gets to pick either inside or outside. Then there is a draw. The Casino wins if the second person can't consistently win. -->


## Introduction

A function is a piece of code that is packaged in a way that makes it easy to reuse. Functions make it easy for you to `filter()`, `arrange()`, `select()`, and create a `tibble()`, as you have seen in Chapters \@ref(visualization) and \@ref(wrangling). Functions also allow you to transform variables and perform mathematical calculations. We use functions like `rnorm()` and `runif()` to generate random draws from a distribution.

every time we reference a function, we include the parentheses. You call a function by including its parentheses and any necessary arguments within those parentheses. This is a correct call of `rnorm()`:

```{r}
rnorm(n = 1)
```

If you run the function name without its parentheses, R will return the code that makes up the function. 

```{r}
rnorm
```

Functions can do all sorts of things. `sample()` takes a vector of values and returns a number of values randomly selected from that vector. You can specify the number of random values with the argument `size`. This call is the equivalent of rolling a die.

```{r}
sample(x = 1:6, size = 1)
```

Functions can also take in other functions as arguments. For example, `replicate()` takes an expression and repeats it `n` times. What if we replicated the rolling of a die ten times?

```{r}
replicate(10, sample(1:6, 1))
```

An especially useful type of function is the family of `map_*` functions, from the **purrr** package, which is automatically loaded with `library(tidyverse)`. These functions apply some other function to every row in a tibble.

```{r, message = FALSE}
library(tidyverse)
```

Let's create a tibble with one variable `x` which takes on three values: 3, 7, and 2.

```{r}
tibble(x = c(4, 16, 9))
```

It is easy to use mutate to create a new variable, `sq_root`, which is the square root of each value of x.

```{r}
tibble(x = c(4, 16, 9)) %>% 
  mutate(sq_root = sqrt((x)))
```

`map_*` functions provide another approach. A `map_*` function takes two required arguments. First is the object over which you want to iterate. This will generally be a column in the tibble you are working in. Second is the function which you want to run for each row in the tibble.

```{r}
tibble(x = c(4, 16, 9)) %>% 
  mutate(sq_root = map_dbl(x, ~ sqrt(.)))
```

`map_dbl()` (pronounced "map-double") took the function `sqrt()` and applied it to each element of `x`. There are two tricky parts to the use of map_* functions. First, you need to put the tilde symbol --- the "~" --- before the name of  the function which you want to call. Without the `~`, you will get an error:

```{r, error = TRUE}
tibble(x = c(4, 16, 9)) %>% 
  mutate(sq_root = map_dbl(x, sqrt(.)))
```

Second, you need to include a period --- the "." --- in the spot where the variable goes. Using the name of the variable --- `x` in this case --- will generate an error.

```{r, error = TRUE}
tibble(x = c(4, 16, 9)) %>% 
  mutate(sq_root = map_dbl(x, ~ sqrt(x)))
```

Tilde and dot --- that is, `~` and `.` --- are easy to forget.

We called these `map_*` functions (plural) before.  If you know the expected output of your function, you can specify that kind of vector:

- `map()`: list  
- `map_lgl()`: logical
- `map_int()`: integer
- `map_dbl()`: double (numeric)
- `map_chr()`: character
- `map_df()`: data frame

Since our example returns numeric output, we use `map_dbl()` instead of `map()`.

The key difference between using `mutate()` and `map_*` functions is that `map_*` functions are designed to work well with lists, both as inputs and as outputs.  `mutate()` is designed for vectors.

## List-columns and map functions

Recall that a list is different from an atomic vector. In atomic vectors, each element of the vector has one value.  Lists, however, can contain vectors, and even more complex objects, as elements.

```{r}
x <- list(c(4, 16, 9))
x
```

`x` is a list with one element. That element is a numeric vector of length 3. We use `[[]]` to extract specific elements. Example:

```{r}
x[[1]][3]
```

The first `[[]]` extracts the first (and only, in this case) element form the list `x`. The second `[[]]`` extracts the 3rd element from the vector which is that first element.


There are a number of built-in R functions that output lists. For example, the ***ggplot*** objects you have been making store all of the plot information in lists. Any function that returns multiple values can be used to create a list output by wrapping those values with `list()`.

```{r}
x <- rnorm(10)

# range() returns the min and max of the argument 

range(x)

tibble(col_1 = list(range(x))) 
```

Notice this is a 1x1 tibble with one observation, which is a list of one element. Voila! You have just created a **list-column**.

*If a function returns multiple values as a vector, like `range()` does, you must use `list()` as a wrapper if you want to create a list-column.*

A list column is a column of your data which is a [list](https://adv-r.hadley.nz/vectors-chap.html#lists) rather than an atomic vector.  Like with lists, you can pipe to `str()` to examine the column more easily.

```{r message=FALSE}
tibble(col_1 = list(range(x))) %>%
  str()
```

<!-- DK: This goes way to fast. We need several simple examples, more or less the same as in the tutorials. -->

Let's practice with the `nhanes` dataset from the **primer.data** package. How could we add a column to the dataset that included the quantiles of the `height` variable for each `gender`?

```{r}
library(primer.data)
```

Select the relevant variables, and group by `gender`. We are grouping because we are curious as to how `height` is distributed in between `gender`. We drop any rows with missing data.

```{r}
nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender)
```

There are two approaches. In the first, we are happy to have an output tibble with just two rows:


```{r}
nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender) %>% 
  summarise(q_height = list(quantile(height)),
            .groups = "drop")
```

Note that there was no need to use `map_*` functions in this case. The simple **dplyr** approach works fine. The only "trick" is the use of `list()` to wrap the output of `quantile()`. Use `str()` to examine the exact values.

```{r}
nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender) %>% 
  summarise(q_height = list(quantile(height)),
            .groups = "drop") %>% 
  str()
```

Men are taller than women throughout the distribution, but the smallest individual (child) in the data, see the 0% quantile, happens to be male.

The second case involves a scenario in which we do not want to "lose" any rows in our tibble. We want a `q_height` column for all the rows, even if the values included are repetitive.  A common scenario is that we want to use `q_height` to perform a calculate for each individual. To do this, we need a `map_*` function.

```{r}
nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender) %>% 
  summarize(q_height = map(height, ~ quantile(.)),
            .groups = "drop")
```

The first four lines of the pipe are the same in both cases. The only difference is the use of `list(quantile(height))` in the first and `map(height, ~ quantile(.)` in the second.

We can use `map_*` functions to both create a list-column and then, much more importantly, work with that list-column afterwards. Example:

<!-- DK: This is a good example. Needs to go slower, or be repeated several times. -->

```{r}
tibble(ID = 1:3) %>% 
  mutate(draws = map(ID, ~ rnorm(10))) %>% 
  mutate(max = map_dbl(draws, ~ max(.))) %>% 
  mutate(range = map(draws, ~ range(.)))
```

This flexibility is only possible via the use of list-columns and  `map_*` functions. This workflow is extremely common. We start with an empty tibble, using ID to specify the number of rows. With that skeleton, each step of the pipe adds a new column, working off a column which already exists. 

<!-- DK: Lots of awkward. -->

Until now, we have practiced using `map_*` functions with built-in R functions. Sometimes, however, there is not an R function which does what we want. When that happens, we need to create our own function.


## Custom Functions

### Creating your own functions

There are many built-in functions in R. You can also create your own custom functions, which may look something like this:

```{r}
add_one_and_one <- function(){
  1 + 1
}

add_one_and_one()
```

You just created a function! This function will return `1 + 1` whenever called. 

Consider a function which adds the number 6 to a value `x`, a value which we want to allow the user provide. 

```{r}
add_six_to_something <- function(x){
  x + 6
}

add_six_to_something(x = 1)
```

You have incorporated your first **formal argument**. Formal arguments in functions are additional parameters that allow the user to customize the use of the function. Instead of adding `1 + 1` over and over again, your function takes in a number `x` that the user defines and adds 6. Consider a function with *two* formal arguments.

```{r}
add_x_to_y <- function(x, y) {
  x + y
}

add_x_to_y(1, 2)
add_x_to_y(4, 3)
```



### Anonymous functions with `map_*` functions

We can create functions that perform operations "on the fly," without bothering to give them a name. These nameless functions are called [anonymous functions.](https://coolbutuseless.github.io/2019/03/13/anonymous-functions-in-r-part-1/)

You can use anonymous functions in conjunction with the `map_*` family of functions. They are commonly used to conduct the same operations repeatedly.

You can call an anonymous function using a `~` operator and then using a `.` to represent the current element. Consider these three approaches: 

```{r}
tibble(old = c(4, 16, 9)) %>% 
  mutate(new_1 = old + 6) %>% 
  mutate(new_2 = map_dbl(old, ~ add_six_to_something(.))) %>% 
  mutate(new_3 = map_dbl(old, ~ (. + 6)))
```

<!-- DK: Explicitly show how rnorm() won't work with just mutate because you get the same answer. -->

All three produce the same answer, as we would expect. Just using `mutate()` is best, as long as it accomplishes your goal. In complex situations, especially those involving simulation, it often won't. Example:

```{r}
tibble(ID = 1:3) %>% 
  mutate(x = rnorm(1))
```

Calling `rnorm()`, or any function with a randon component, does not have the effect which you probably want if you do it in the context of a simple `mutate()`. Instead, R runs `rnorm(1)` once, and then copies the value generated to the remaining two rows of the tibble. To get a different value in each row, you need to explicitly tell R to do that:

```{r}
tibble(ID = 1:3) %>% 
  mutate(x = rnorm(1)) %>% 
  mutate(y = map_dbl(ID, ~ rnorm(1)))
```


Note that the parentheses in the anonymous function are not necessary. As long as everything after the `~` works as R code, the anonymous function should work, each time replace the `.` with the value of the relevant value of the `.x` variable --- which is `old` in this case --- with its value in that row.

```{r}
tibble(old = c(4, 16, 9)) %>% 
  mutate(new = map_dbl(old, ~ . + 1))
```


### Skateboard >> perfectly formed rear-view mirror

This image --- widely attributed to the Spotify development team --- conveys an important point.

```{r echo = FALSE, out.width = "60%", fig.align='center', fig.cap = "From [Your ultimate guide to Minimum Viable Product (+great examples)](https://blog.fastmonkeys.com/2014/06/18/minimum-viable-product-your-ultimate-guide-to-mvp-great-examples/)"}
knitr::include_graphics("03-functions/images/mvp.jpg")
```

Build that skateboard before you build the car or some fancy car part. A limited-but-functioning thing is very useful. It also keeps spirits high.

This is related to the valuable Telescope Rule:

> It is faster to make a four-inch mirror and then a six-inch mirror than it is to make a six-inch mirror.

## `no_NA_sampler()`

Assume that we want to sample 10 observations for `height` from the `nhanes` tibble from the **primer.data** package. That is easy to do with the built in function `sample()`.

```{r}
sample(nhanes$height, size = 10)
```

One problem with this approach is that it will sample missing values of `height`. We can avoid that by manipulating the vector inside of the call to `sample()`.

```{r}
sample(nhanes$height[! is.na(nhanes$height)], size = 10)
```

That works, but, first, it is ugly code. And, second, it is hard to extend when we have more constraints. For example, assume we only want to sample from individuals who have no missing values for any variables, not just `height`. To do that, we really ought to make a custom function. Call that function `no_NA_sampler()`.

The first step in function creation is to write code in a normal pipe which does what you want the function to do. In this case, that code would look like:

```{r}
nhanes %>% 
  drop_na() %>%
  sample_n(10) %>% 
  pull(height)
```

We start with `nhanes`, use `drop_na()` to remove rows with missing values for any variable, sample 10 rows at random and then pull out `height`. To turn this into a function, we just need to copy/paste this pipe within the body of our function definition:

```{r}
no_NA_sampler <- function(){
  nhanes %>% 
    drop_na() %>%
    sample_n(10) %>% 
    pull(height)
}

no_NA_sampler()
```

Voila! A function just executes the code within its body. The first step in building a function is not to write the function. It is to write the code which you want the function to execute.

The first version, however, "hard codes" a lot of options which we might want to change. What if we want to sample 5 values of height or 500? In that case, we could hard code a new number in place of "10". A better option would be to add an argument so that we can pass in whatever value we want.

```{r}
no_NA_sampler <- function(n){
  nhanes %>% 
    drop_na() %>%
    sample_n(n) %>% 
    pull(height)
}

no_NA_sampler(n = 2)
no_NA_sampler(n = 25)
```

What if we want to sample from a different variable than `height` or from a different tibble than `nhanes`? Again, the trick is to turn hard coded values into arguments. The argument `tbl` is a placeholder for a data set, `n` for the number of samples you want extracted from your data set, and `var` for the variable in the samples that we are studying.

```{r}
no_NA_sampler <- function(tbl, var, n){
  tbl %>% 
    drop_na() %>%
    sample_n(n) %>% 
    pull({{var}})
}

no_NA_sampler(tbl = nhanes, var = height, n = 2)
```

R does not know how to interpret something like `age` when it is passed in an argument. The double curly braces around `var` tell R, in essence, that `var` is a variable in the tibble created from sampling from our input tibble (`tbl`). We use the order of the arguments, without naming them, with `no_NA_sampler()`, just as with any other R function:

```{r}
no_NA_sampler(trains, age, 5)
```


<!-- DK: I realize that the above is a lousy explanation. Feel free to change it completely. -->

Now that we have the function doing what we want, we should add some comments and some error checking.

```{r}
no_NA_sampler <- function(tbl, var, n){
  
  # Function for grabbing `n` samples from a variable `var` which lives in a
  # tibble `tbl`. 
  
  # I could not figure out how to check to see if `var` actually lives in tibble
  # in my error checking. Also, I don't like that I need to use is_double() as
  # the check on `n` even though I want `n` to be an integer.
  
  stopifnot(is_tibble(tbl))
  stopifnot(is_double(n))

  tbl %>% 
    drop_na() %>%
    
    # What happens if n is "too large"? That is, I need to think harder about a)
    # whether or not I am sampling with or without replacement and b) which I
    # should be doing.
    
    sample_n(size = n) %>% 
    pull({{var}})
}
```

## Prediction Game

Let's play a prediction game. Consider the `kenya` tibble from **primer.data**.

```{r}
kenya
```

The game is that we will pick a random value of `rv13`, which is the number of people who live in the vicinity of a polling station. You guess a number. I guess a number. The winner of the Prediction Game is the person whose guess is closest to the random value selected. Example:

```{r}
your_guess <- 500
my_guess <- 600

sampled_value <- no_NA_sampler(kenya, rv13, n = 1) 

your_error <- abs(your_guess - sampled_value)
my_error <- abs(my_guess - sampled_value)

if(your_error < my_error) cat("You win!")
if(your_error > my_error) cat("I win!")
```


Run this code in your R Console to try it out. It works! It is also sloppy and disorganized. *The first step in writing good code is to write bad code*.

We don't want to play the Prediction Game just once. We want to play it thousands of times. Copy/pasting this code a thousand times would be stupid. Instead, we need a function. Just place the working code within a function definition, and Voila!

```{r}
prediction_game <- function(){
  your_guess <- 500
  my_guess <- 600
  
  sampled_value <- no_NA_sampler(kenya, rv13, n = 1) 
  
  your_error <- abs(your_guess - sampled_value)
  my_error <- abs(my_guess - sampled_value)
  
  if(your_error < my_error) cat("You win!")
  if(your_error > my_error) cat("I win!")
}
```

Other than the function definition itself, there are no changes. Yet, by creating a function, we can now easily run this many times.


```{r}
replicate(3, prediction_game())
```

The problem with this version is that we want `prediction_game()` to *return* a message about the winner. Right now, it returns nothing. It just prints the winner. Let's change that, and also allow for guesses to be passed in as an argument, along with the tibble and variable. We can leave `n` hard coded as 1 since, by definition, the Prediction Game is an attempt to guess one number, at least for now. To do this, we need to use the `return()` function which, when executed, causes the function to finish and return whatever value is within the paratheses. 

<!-- DK: Add some code comments, especially {{var}} -->


```{r}
prediction_game <- function(guesses, tbl, var){
  
  # Check to make sure that guesses is a vector of doubles of length 2.
  
  stopifnot(all(is_double(guesses)))
  stopifnot(length(guesses) == 2)
  
  # This tells the function that the "guess" inputted first in the 
  # guesses is "your" guess, whereas the second input is "my" guess.
  
  your_guess <- guesses[1]
  my_guess <- guesses[2]
  
  # Use the function no_NA_sampler to draw a sample from a data set
  # of our choosing, with a {{var}} and n.
  
  sampled_value <- no_NA_sampler(tbl, {{var}}, n = 1) 
  
  # Subtract the sampled value obtained from no_NA_sampler from 
  # both of our guesses. 
  
  your_error <- abs(your_guess - sampled_value)
  my_error <- abs(my_guess - sampled_value)
  
  # If the difference between your guess and the sampled value is 
  # less than the difference between my guess and the sampled value
  # (meaning that your guess was closer to the truth), the function
  # returns the message "Guess, your_guess, wins!".
  
  if(your_error < my_error){ 
    return(paste("Guess", your_guess, "wins!"))
  }
  
  # If your error exceeds my error (meaning that your guess was
  # further than the truth than mine), the function prints the 
  # message "Guess, my_guess, wins!" 
  
  if(your_error > my_error){ 
    return(paste("Guess", my_guess, "wins!"))
  }
  
  # If we guess the same number, and our error rates are therefore
  # identical, we return the message "A tie!". 
  
  if(your_error == my_error){ 
    return("A tie!")
  }

}
```

```{r}
replicate(5, prediction_game(guesses = c(500, 600), kenya, rv13))
```


In general, we will want to store the results in a tibble, which makes later analysis and plotting easier.

```{r}
tibble(ID = 1:3) %>% 
  mutate(result = map_chr(ID, ~ 
                            prediction_game(guesses = c(500, 600),
                                            kenya, 
                                            rv13)))
```

Who wins the game the most if we play 1,000 times?

```{r, echo = FALSE}
set.seed(9)
```


```{r}
tibble(ID = 1:1000) %>% 
  mutate(result = map_chr(ID, ~ 
                            prediction_game(guesses = c(500, 600),
                                            kenya, 
                                            rv13))) %>% 
  ggplot(aes(result)) +
    geom_bar()
```

It is hardly surprising that 500 wins more often than 600 since the mean of `rv13` is `r mean(kenya$rv13)`. The mean seems like a pretty good guess! But it is not the best guess. 

To test whether the mean or the median is a better guess, we will use our created `prediction_game` function with the guesses of 442 (the median) and 539 (the mean) and plot the results. 

```{r}
tibble(ID = 1:1000) %>% 
  mutate(result = map_chr(ID, 
                          ~ prediction_game(c(442, 539),
                                            kenya,
                                            rv13))) %>% 
  ggplot(aes(result)) +
    geom_bar()
```

The mean is not a bad prediction. But the best prediction is (surprisingly?) the median, which is `r median(kenya$rv13)`.

#### Playing within a tibble

In other cases, it is more convenient to play portions of the Prediction Game within a tibble. Imagine that we are trying to guess the biggest value out of 10 random samples. 

```{r}
tibble(ID = 1:3, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10)))
```

We can now manipulate the `result` column and then see which prediction did better. Using the same structure as before, we subtract our guesses from the variable we were guessing; in this case, the biggest value in 10 random samples.  

```{r}
tibble(ID = 1:3, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10))) %>% 
  mutate(biggest = map_dbl(result, ~ max(.))) %>% 
  mutate(error_1 = abs(guess_1 - biggest)) %>% 
  mutate(error_2 = abs(guess_2 - biggest)) %>% 
  mutate(winner = case_when(error_1 < error_2 ~ "Guess one wins!",
                            error_1 > error_2 ~ "Guess two wins!",
                            TRUE ~ "A tie!"))
```

Run the test 1,000 times.

```{r}
tibble(ID = 1:1000, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10))) %>% 
  mutate(biggest = map_dbl(result, ~ max(.))) %>% 
  mutate(error_1 = abs(guess_1 - biggest)) %>% 
  mutate(error_2 = abs(guess_2 - biggest)) %>% 
  mutate(winner = case_when(error_1 < error_2 ~ "Guess one wins!",
                            error_1 > error_2 ~ "Guess two wins!",
                            TRUE ~ "A tie!")) %>% 
  ggplot(aes(winner)) +
    geom_bar()
```

Empirically, we see than 900 is a much better guess than 800. Instead of calling a function to be run 1,000 times, we just performed each step within each row of a tibble with 1,000 rows. Both approaches work. The best choice depends on the context of your problem.

## Summary

*The first step in writing good code is to write bad code*.

### Lists and list-columns

- A list is different from an atomic vector. Atomic vectors are familiar to us: each element of the vector has one value, and thus if an atomic vector is a column in your data set, each observation gets a single value.  Lists, however, can contain vectors, and other more complex objects, as elements.
- There are various ways to create lists. The most common is to use the `list()` function to "wrap" some object. `map()` always returns a list.
- We can take a list column and, by applying an anonymous function to it with `map()`, create another list column. This is similar to taking a tibble and piping it into a function, like  `mutate()`, which returns a new tibble to work with.
- You can also use `map_*` functions to take a list column as an input and return an atomic vector -- a column with a single value per observation -- as an output. 

*If a function returns multiple values as a vector, you must use `list()` as a wrapper if you want to create a list-column.*

### Writing functions

- Optimize usefulness by adding more formal arguments when needed. A function that only gives an option for `n` may not be as helpful as a function that allows us to enter options for a data set, variable, and n value. 
- Give your arguments sensible names.  
- By default, a function returns the result of the last line of the body. Use `return()` to override this default.
- When starting a function, remember that smaller steps are easier than trying to build everything in one motion. In general: start by writing the body, test the body in a basic function, and then add formal arguments.  
- Use double curly braces around `var`s, since R does not know how to interpret variable names when they are passed in an argument. The double curly braces tell R that `var` is a variable in a tibble.  


### Distributions


- The word "distribution" can mean two things. First, it is an object --- a mathematical formula, an imaginary urn --- from which you can draw values. Second, it is a list of such values.   
- The two most important aspects of a distribution are its *center* and its *variability*.
- The median is often a more stable measure of the center than the mean. The mad (scaled median absolute deviation) is often a more stable measure of variation than the standard deviation. 
- Outliers cause a lack a stability. In a distribution without outliers, the mean/median and mad/sd are so close in value that it does not matter much which ones you use.



