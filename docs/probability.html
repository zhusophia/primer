<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Probability | Preceptor’s Primer for Bayesian Big Data Science</title>
<meta name="author" content="David Kane">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.5.3/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script><script src="libs/plotly-binding-4.9.2.1/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet">
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Preceptor’s Primer for Bayesian Big Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preamble.html">Preamble</a></li>
<li><a class="" href="shopping-week.html">Shopping Week</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">1</span> Visualization</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">2</span> Wrangling</a></li>
<li><a class="" href="functions.html"><span class="header-section-number">3</span> Functions</a></li>
<li><a class="" href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></li>
<li><a class="active" href="probability.html"><span class="header-section-number">5</span> Probability</a></li>
<li><a class="" href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></li>
<li><a class="" href="two-parameters.html"><span class="header-section-number">7</span> Two Parameters</a></li>
<li><a class="" href="three-parameters.html"><span class="header-section-number">8</span> Three Parameters</a></li>
<li><a class="" href="four-parameters.html"><span class="header-section-number">9</span> Four Parameters</a></li>
<li><a class="" href="five-parameters.html"><span class="header-section-number">10</span> Five Parameters</a></li>
<li><a class="" href="n-parameters.html"><span class="header-section-number">11</span> N Parameters</a></li>
<li><a class="" href="case-studies.html"><span class="header-section-number">12</span> Case Studies</a></li>
<li><a class="" href="tools.html">Tools</a></li>
<li><a class="" href="shiny.html">Shiny</a></li>
<li><a class="" href="maps.html">Maps</a></li>
<li><a class="" href="animation.html">Animation</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PPBDS/primer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="probability" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Probability<a class="anchor" aria-label="anchor" href="#probability"><i class="fas fa-link"></i></a>
</h1>
<!-- Add 3D distribution for Two Models case. Old picture is wrong because of change in percentages. Need regular plot at end as well. -->
<!-- Add 3D distribution for Three Models case? -->
<!-- Consider plotting the rayshaders live. Key command may be  rgl::rglwidget(). -->
<!-- More animations. Create a movie which swoops into the joint distribution, takes a slice, remove the other slices, and then normalizes. Cool new package ggral (sp?) -->
<!-- Need more of a parallel structure to 2 models, 3 models and N models. They should all be much more like each other. Three models is currently the best of them. Also, each needs to use the posterior distribution to forecast something. Structure for all three: Create joint distribution. Create conditional (unnormalized) distribution. Create posterior. Use posterior. Show code for all steps. -->
<!-- Greek letters are for parameters which we can never observe. Latin letters are for observables. -->
<!-- Also good to get into the *scaling* of distributions, and the arbitrariness thereof. For example, trains$age is a distribution. Fine. What about rep(trains$age, 2)? What about rep(trains$age, 100)? Well, if any vector is a distribution, then all three of these are distributions. In fact, they are the same distribution, just scaled differently.  -->
<!-- Need more discussion about quintiles and area under the curve. -->
<!-- When discussing a parameter $p$ and a probability distribution p() in the absence of a specific context, then those simple terms are OK. But, whenever you are talking about specific parameters or specific probability distributions, you should have either subscripts or items in the parentheses, respectively.  -->
<!-- Revisit these references and see if there is other stuff we should include:   -->
<!-- Teaching Bayes' Rule: A Data-Oriented Approach by Jim Albert. -->
<!-- Rethinking Chapter 2. Garden of forking data is just excellent stuff. -->
<!-- Bayesian Workshop -->
<p> </p>
<blockquote>
<p>The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at ten he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred. -— Immanuel Kant, <em>Critique of Pure Reason</em></p>
</blockquote>
<p>The central tension, and opportunity, in data science is the interplay between the <em>data</em> and the <em>science</em>, between our empirical observations and the models which we use to understand them. Probability is the language we use to explore that interplay; it connects models to data, and data to models.</p>
<div id="probability-distributions" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Probability distributions<a class="anchor" aria-label="anchor" href="#probability-distributions"><i class="fas fa-link"></i></a>
</h2>
<div class="figure">
<span id="fig:unnamed-chunk-350"></span>
<img src="05-probability/images/probability_dice.jpeg" alt="Dice and Probability." width="100%"><p class="caption">
FIGURE 5.1: Dice and Probability.
</p>
</div>
<p>What does it mean that Trump had a <em>30% chance</em> of winning re-election in the fall of 2020? That there is a <em>90% probability</em> of rain today? That the dice at the casino are <em>unfair</em>?</p>
<p>Probability is about quantifying uncertainty. We can think of probability as a proportion. The probability of an event occurring is a number from 0 to 1, where 0 means that the event is impossible and 1 means that the event is 100% certain.</p>
<p>Let’s begin with the simplest events: coin flips and dice rolls. If the dice and the coins are fair, we can operate under the assumption that all outcomes are equally likely.</p>
<p>This allows us to make the following statements:</p>
<ul>
<li>The probability of rolling a 1 or a 2 is 2/6, or 1/3.</li>
<li>The probability of rolling a 1, 2, 3, 4, 5, or 6 is 1.<br>
</li>
<li>The probability of flipping a coin and getting tails is 1/2.</li>
</ul>
<!-- DK: What is the difference between a distribution and a probability distribution? After all, we can define them both with draws. And the draws can look like anything. And you can turn any distribution into a probability distribution via normalization. --><p>For the purposes of this <em>Primer</em>, a <em>probability distribution</em> is a mathematical object that covers a set of outcomes, where each distinct outcome has a chance of occurring between 0 and 1 inclusive. The chances must sum to 1. The set of possible outcomes — heads or tails for the coin, 1 through 6 for a single die, 2 through 12 for a pair of dice — can be either discrete or continuous. This set of outcomes is the <em>domain</em> of the probability distribution. There are three types of probability distributions: mathematical, empirical, and posterior.</p>
<p>The key difference between a distribution, as we have explored them in earlier chapters, and a <em>probability</em> distribution is the requirement that the sum of the probabilities of the individual outcomes must be exactly 1. There is no such requirement in a distribution. But any distribution can be turned into a probability distribution by “normalizing” it, as we will explore. In this context, we will often refer to a distribution which is not (yet) a probability distribution as an “unnormalized” distribution.</p>
<p>Pay attention to notation. Whenever we are talking about a specific probability (represented by a single value), we will use <span class="math inline">\(\rho\)</span> (the Greek letter “rho” but spoken aloud as “p” by us) with a <em>subscript</em> which specifies the exact outcome of which it is the probability. For instance, <span class="math inline">\(\rho_h = 0.5\)</span> denotes the probability of getting heads on a coin toss when the coin is fair. <span class="math inline">\(\rho_t\)</span> — spoken as “PT” or “P sub T” or “P tails” — denotes the probability of getting tails on a coin toss. However, when we are referring to the entire probability distribution over a set of outcomes, we will use <span class="math inline">\(\text{Prob}()\)</span>. For example, the probability distribution of a coin toss is <span class="math inline">\(\text{Prob}(\text{coin})\)</span>. That is, <span class="math inline">\(\text{Prob}(\text{coin})\)</span> is composed of the two specific probabilities (50% and 50%) mapped from the two values in the domain: Heads and Tails. Similarly, <span class="math inline">\(\text{Prob}(\text{sum of two dice})\)</span> is the probability distribution over the set of 11 outcomes (2 through 12) which are possible when you take the sum of two dice. <span class="math inline">\(\text{Prob}(\text{sum of two dice})\)</span> is made up of 11 numbers — <span class="math inline">\(\rho_2\)</span>, <span class="math inline">\(\rho_3\)</span>, …, <span class="math inline">\(\rho_{12}\)</span> — each representing the unknown probability that the sum will equal their value. That is, <span class="math inline">\(\rho_2\)</span> is the probability if rolling a 2.</p>
<!-- DK: Above is not clear. Explain this better by showing that a distribution is just a vector. A probability distribution is a vector in which each element of the vector is mapped to a 0--1 probability, the sum of which is one. Need to connect this more clearly to joint distribution discussion. -->
<div id="flipping-a-coin" class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> Flipping a coin<a class="anchor" aria-label="anchor" href="#flipping-a-coin"><i class="fas fa-link"></i></a>
</h3>
<p>A <em>mathematical distribution</em> is based on mathematical formulas. Assuming that the coin is perfectly fair, we should, on average, get heads as often as we get tails.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-351-1.png" width="100%"></div>
<p>An <em>empirical distribution</em> is based on data. You can think of this as the probability distribution created by running a simulation. In theory, if we increase the number of coins we flip in our simulation, the empirical distribution will look more and more similar to the mathematical distribution. The probability distribution is the Platonic form. The empirical distribution will often look like the mathematical probability distribution, but it will rarely be exactly the same.</p>
<p>In this simulation, there are 56 heads and 44 tails. The outcome will vary every time we run the simulation, but the proportion of heads to tails should not be too different if this coin is fair.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-352-1.png" width="100%"></div>
<p>A <em>posterior distribution</em> is based on beliefs and expectations. It displays your belief about things you can’t see right now. You may have posterior distributions for events in the past, present, or future.</p>
<p>In the case of the coin toss, the posterior distribution changes depending on your beliefs. For instance, let’s say your friend brought a coin to school and asked to bet you. If the result is heads, you have to pay them $5.</p>
<p>This makes you suspicious; your posterior distribution would reflect this. You might believe that <span class="math inline">\(\rho_h\)</span> is 0.95 and <span class="math inline">\(\rho_t\)</span> is 0.05.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-353-1.png" width="100%"></div>
<p>The full terminology is mathematical (or empirical or posterior) <em>probability</em> distribution. But we will often shorten this to just mathematical (or empirical or posterior) distribution. The word “probability” is understood, even if it is not present.</p>
</div>
<div id="rolling-two-dice" class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> Rolling two dice<a class="anchor" aria-label="anchor" href="#rolling-two-dice"><i class="fas fa-link"></i></a>
</h3>
<p>Our <em>mathematical distribution</em> tells us that, with a fair dice, the probability of getting 1, 2, 3, 4, 5, and 6 are equal: there is a 1/6 chance of each. When we roll two dice at the same time and sum the numbers, the values closest to the middle are more common than values at the edge because there are more combinations of numbers that add up to the middle values.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-354-1.png" width="100%"></div>
<p>We get an <em>empirical distribution</em> by running a simulation and rolling two dice a hundred times. The result is not identical to the mathematical distribution because of the inherent randomness of the real world.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-355-1.png" width="100%"></div>
<p>We might consider labeling the y-axis in plots of empirical distributions as “Proportion” rather than “Probability” since it is an actual proportion, calculated from real (or simulated) data. We will keep it as “Probability” since we want to emphasize the parallels between mathematical, empirical and posterior probability distributions.</p>
<p>The <em>posterior distribution</em> for rolling two dice a hundred times depends on your expectations. If you take the dice from your Monopoly set, you have reason to believe that the assumptions underlying the mathematical distribution are true. However, if you walk into a crooked casino and a host asks you to play craps, you might be suspicious. In craps, a come-out roll of 7 and 11 is a “natural,” resulting in a win for the “shooter” and a loss for the casino. You might expect those numbers to occur less often than they would with fair dice. Meanwhile, a come-out roll of 2, 3 or 12 is a loss for the shooter. You might also expect values like 2, 3 and 12 to occur more frequently. Your posterior distribution might look like this:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-356-1.png" width="100%"></div>
<p>Someone less suspicious of the casino would have a posterior distribution which looks more like the mathematical distribution.</p>
</div>
<div id="presidential-elections" class="section level3" number="5.1.3">
<h3>
<span class="header-section-number">5.1.3</span> Presidential elections<a class="anchor" aria-label="anchor" href="#presidential-elections"><i class="fas fa-link"></i></a>
</h3>
<p>Now let’s say we are building probability distributions for political events, like a presidential election. We want to know the probability that Democratic candidate wins X electoral votes, where X comes from the range of possible outcomes: 0 to 538. (The total number of electoral votes in US elections since 1964 is 538.)</p>
<p>We can start with a <em>mathematical distribution</em> for X which assumes that the chances of the Democratic candidate winning any given state’s electoral votes is 0.5 and the results from each state are independent.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-357-1.png" width="100%"></div>
<p>We know that campaign platforms, donations, charisma, and many other factors will contribute to a candidate’s success. Elections are more complicated than coin tosses. We also know that many presidential elections in history have resulted in much bigger victories or defeats than this distribution seems to allow for.</p>
<p>The <em>empirical distribution</em> in this case could involve looking into past elections in the United States and counting the number of electoral votes that the Democrats won in each. For the empirical distribution, we create a tibble with electoral vote results from past elections. Looking at elections since 1964, we can observe that the number of electoral votes that the Democrats received in each one is different. Given that we only have 15 entries, it is difficult to draw conclusions or make predictions based off of this empirical distribution.</p>
<p>However, this model is enough to suggest that the assumptions of the mathematical probability distribution above do not work for electoral votes. The model assumes that the Democrats have a 50% chance of receiving each of the 538 votes. Just looking at the mathematical probability distribution, we can observe that receiving 13 or 17 or 486 votes out of 538 would be extreme and almost impossible under this mathematical model. However, our empirical distribution tells us that those were real election results.</p>
<!-- DK: Need to add 2020 -->
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-358-1.png" width="100%"></div>
<p>The <em>posterior distribution</em> of electoral votes is a popular topic, and an area of strong disagreement, among data scientists. Consider this posterior from <em>FiveThirtyEight</em>.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-359-1.png" width="100%"></div>
<p>Here is a posterior from the FiveThirtyEight website from August 13, 2020. This was created using the same data as the above distribution, but simply displayed differently. For each electoral result, the height of the bar represents the probability that a given event will occur. However, there are no lablels y-axis telling us what the specific probability of each outcome is. And that is OK! The specific values are not that useful. If we removed the labels on our y-axes, would it matter?</p>
<div class="inline-figure"><img src="05-probability/images/fivethirtyeight.png" width="100%"></div>
<p>Here is the posterior from <em>The Economist</em>, also from August 13, 2020. This looks confusing at first because they chose to merge the axes for Republican and Democratic electoral votes. We can tell that <em>The Economist</em> was less optimistic, relative to <em>FiveThirtyEight</em>, about Trump’s chances in the election.</p>
<div class="inline-figure"><img src="05-probability/images/economist_aug13.png" width="100%"></div>
<p>These two models, built by smart people using similar data sources, have reached fairly different conclusions. Data science is difficult! There is not one “right” answer. Real life is not a problem set.</p>
<div class="figure">
<span id="fig:unnamed-chunk-362"></span>
<img src="05-probability/images/538_versus_Economist.png" alt="Watch the makers of these two models throw shade at each other on Twitter! Eliot Morris is one of the primary authors of the Economist model. Nate Silver is in charge of 538. They don't seem to be too impressed with each other's work! More smack talk [here](https://statmodeling.stat.columbia.edu/2020/08/31/more-on-that-fivethirtyeight-prediction-that-biden-might-only-get-42-of-the-vote-in-florida/) and [here](https://statmodeling.stat.columbia.edu/2020/08/31/problem-of-the-between-state-correlations-in-the-fivethirtyeight-election-forecast/)." width="100%"><p class="caption">
FIGURE 5.2: Watch the makers of these two models throw shade at each other on Twitter! Eliot Morris is one of the primary authors of the Economist model. Nate Silver is in charge of 538. They don’t seem to be too impressed with each other’s work! More smack talk <a href="https://statmodeling.stat.columbia.edu/2020/08/31/more-on-that-fivethirtyeight-prediction-that-biden-might-only-get-42-of-the-vote-in-florida/">here</a> and <a href="https://statmodeling.stat.columbia.edu/2020/08/31/problem-of-the-between-state-correlations-in-the-fivethirtyeight-election-forecast/">here</a>.
</p>
</div>
<p>There are many political science questions you could explore with posterior distributions. They can relate to the past, present, or future.</p>
<ul>
<li>Past: How many electoral votes would Hilary Clinton have won if she had picked a different VP?</li>
<li>Present: What are the total campaign donations from Harvard faculty?</li>
<li>Future: How many electoral votes will the Democratic candidate for president win in 2024?</li>
</ul>
</div>
<div id="continuous-distributions" class="section level3" number="5.1.4">
<h3>
<span class="header-section-number">5.1.4</span> Continuous distributions<a class="anchor" aria-label="anchor" href="#continuous-distributions"><i class="fas fa-link"></i></a>
</h3>
<!-- DK: More details? -->
<p>The three examples above are all <em>discrete</em> probability distributions, meaning that the outcome variable can only take on a limited set of values. A coin flip has two outcomes. The sum of a pair of dice has 11 outcomes. The total electoral votes for the Democratic candidate has 539 possible outcomes. In the limit, we can also create <em>continuous</em> probability distributions which have an <em>infinite</em> number of possible outcomes. For example, the percentage of Americans who “approve” of the job that President Biden is doing is a continuous variable, meaning it can take on any value between 0 and 1.</p>
<p>All the characteristics for discrete probability distributions which we reviewed above apply just as much to continuous probability distributions. For example, we can create mathematical, empirical and posterior probability distributions for continuous outcomes just as we did for discrete outcomes. For example, a posterior probability distribution for <span class="math inline">\(p\)</span>, the percentage of US citizens who approve of Biden, might look like:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-363-1.png" width="100%"></div>
<p>Comments:</p>
<!-- DK: Need X Files poster -->
<ul>
<li><p><em>The truth is out there.</em> If we asked all 300+ million Americans whether or not they approve of President Biden, we could know <span class="math inline">\(p\)</span> exactly. Alas, we can’t do that. We use a posterior probability distribution to summarize are beliefs about the true value of <span class="math inline">\(p\)</span>, a truth we can never confirm.</p></li>
<li><p><em>Continuous variables are a myth.</em> Nothing that can be represented on a computer is <a href="https://cs.stackexchange.com/questions/71648/why-is-data-in-computer-science-considered-to-be-discrete">truly continuous</a>. Even something which appears continuous, like <span class="math inline">\(p\)</span>, actually can only take on a (very large) set of discrete variables. In this case, there are approximately 300 million possible true values of <span class="math inline">\(p\)</span>, one for each total number of people who approve of President Biden.</p></li>
<li><p>The math of continuous probability distributions can be tricky. Read <a href="https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view">a book</a> on mathematical probability for all the messy details. Little of that matters in applied work.</p></li>
<li><p>The most important difference is that, with discrete distributions, it makes sense to estimate the probability of a specific outcome. What is the probability of rolling a 9? With continuous distributions, this makes no sense because there are an infinite number of possible outcomes. <em>With continuous variables, we only estimate intervals.</em> What is the probabilty that Biden’s true approval percentage is between 50% and 55%?</p></li>
</ul>
<p>Don’t worry about the distinctions between discrete and continuous outcomes, or between the discrete and continuous probability distributions which we will use to summarize our beliefs about those outcomes. The basic intuition is the same in both cases.</p>
</div>
<div id="working-with-probability-distributions" class="section level3" number="5.1.5">
<h3>
<span class="header-section-number">5.1.5</span> Working with probability distributions<a class="anchor" aria-label="anchor" href="#working-with-probability-distributions"><i class="fas fa-link"></i></a>
</h3>
<!-- DK: Does this really belong here? Maybe at the end? -->
<div class="figure">
<span id="fig:unnamed-chunk-364"></span>
<img src="05-probability/images/de_finetti.jpg" alt='Bruno de Finetti, an Italian statistician who wrote a famous treatise on the theory of probability that began with the statement "PROBABILITY DOES NOT EXIST." This is because probability only exists subjectively in our minds.' width="100%"><p class="caption">
FIGURE 5.3: Bruno de Finetti, an Italian statistician who wrote a famous treatise on the theory of probability that began with the statement “PROBABILITY DOES NOT EXIST.” This is because probability only exists subjectively in our minds.
</p>
</div>
<p>A probability distribution is not always easy to work with. It is a complex object. And, in many contexts, we don’t really care about all that complexity. So, instead of providing the full probability distribution, we often just use a summary measure, a number or two or three which captures those aspects of the entire distribution which are relevant to the matter at hand. Let’s explore these issues using the 538 posterior probability distribution, as of August 13, 2020, for the number of electoral votes which will be won by Joe Biden. Here is a tibble with 1,000,000 draws from that distribution:</p>
<div class="sourceCode" id="cb519"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">draws</span></code></pre></div>
<pre><code>## # A tibble: 1,000,000 x 2
##       ID electoral_votes
##    &lt;int&gt;           &lt;int&gt;
##  1     1             327
##  2     2             297
##  3     3             413
##  4     4             319
##  5     5             151
##  6     6             337
##  7     7             210
##  8     8             435
##  9     9             201
## 10    10             325
## # … with 999,990 more rows</code></pre>
<p><em>A distribution and a sample of draws from that distribution are different things.</em> But, if you squint, they are sort of the same thing, at least for our purposes. For example, if you want to know the mean of the distribution, then the mean of the draws will be a fairly good estimate, especially if the number of draws is large enough.</p>
<p>Recall from Chapter <a href="wrangling.html#wrangling">2</a> how we can draw randomly from specified probability distributions:</p>
<div class="sourceCode" id="cb521"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1] -0.780 -0.068  1.003 -0.508  0.937  0.603 -0.518  0.232 -0.469 -1.128</code></pre>
<div class="sourceCode" id="cb523"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1] 0.33 0.94 0.53 0.11 0.39 0.32 0.67 0.41 0.65 0.53</code></pre>
<p>The elements of these vectors are all “draws” from the specified probability distributions. In most applied situations, our tools will produce draws rather than summary objects. Fortunately, a vector of draws is very easy to work with. Start with summary statistics:</p>
<div class="sourceCode" id="cb525"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">key_stats</span> <span class="op">&lt;-</span> <span class="va">draws</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>mn <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            md <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            mad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/mad.html">mad</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span><span class="op">)</span>

<span class="va">key_stats</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##      mn    md    sd   mad
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  325.   326  86.9  101.</code></pre>
<p>Calculate a 95% interval directly:</p>
<div class="sourceCode" id="cb527"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">draws</span><span class="op">$</span><span class="va">electoral_votes</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## 2.5%  98% 
##  172  483</code></pre>
<p>Approximate the 95% interval in two ways:</p>
<div class="sourceCode" id="cb529"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">key_stats</span><span class="op">$</span><span class="va">mn</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">sd</span>, 
  <span class="va">key_stats</span><span class="op">$</span><span class="va">mn</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">sd</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 152 499</code></pre>
<div class="sourceCode" id="cb531"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">key_stats</span><span class="op">$</span><span class="va">md</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">mad</span>, 
  <span class="va">key_stats</span><span class="op">$</span><span class="va">md</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">mad</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 124 528</code></pre>
<p>In this case, using the mean and standard deviation produces a 95% interval which is closer to the true interval. In other cases, the median and scaled median absolute deviation will do better. Either approximation is generally “good enough” for most work. But, if you need to know the exact 95% interval, you must use <code><a href="https://rdrr.io/r/stats/quantile.html">quantile()</a></code>.</p>
</div>
<div id="unnormalized-distributions" class="section level3" number="5.1.6">
<h3>
<span class="header-section-number">5.1.6</span> Unnormalized distributions<a class="anchor" aria-label="anchor" href="#unnormalized-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>Remember that <em>probability distributions are mathematical objects that cover a set of outcomes, where each outcome in the domain is mapped to a probability value between 0 and 1 inclusive and the sum of all mappings is 1.</em> Sometimes, you may see distributions similar to probability distributions, only the y-axis displays raw counts instead of proportions. Unnormalized distributions are not probability distributions, but it is easy to convert between the two. You simply divide all the outcome counts on the y-axis by the sum of all outcome counts to “normalize” the unnormalized distribution. Unnormalized distributions are often an intermediary step; it is sometimes handy to work with counts until the very end.</p>
<!-- DK: Do we really need this?  -->
<p>For instance, we can generate the following unnormalized distribution for the sum of rolling two dice.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-372-1.png" width="100%"></div>
<p>Notice that the shape of the distribution is the same as the empirical probability distribution we generated earlier, except that the y-axis is labeled differently.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-373-1.png" width="100%"></div>
<p>The two plots — unnormalized and normalized — have the exact same shape. In many ways, they are the same object. Yet normalization is required if we want to work with a probability distribution.</p>
</div>
<div id="joint-distributions" class="section level3" number="5.1.7">
<h3>
<span class="header-section-number">5.1.7</span> Joint distributions<a class="anchor" aria-label="anchor" href="#joint-distributions"><i class="fas fa-link"></i></a>
</h3>
<!-- DK: Should be p(A). Discuss p(A, B). Find a better example.  -->
<p>Recall that <span class="math inline">\(\text{Prob}(\text{coin})\)</span> is the probability distribution for the result of a coin toss. It includes two parts, the probability of heads (<span class="math inline">\(\rho_h\)</span>) and the probability of tails (<span class="math inline">\(\rho_t\)</span>). This is a <em>univariate</em> distribution because there is only one outcome, which can be heads or tails. If there is more than one outcome, then we have a <em>joint</em> distribution.</p>
<!-- DK: Use of "outcome" is sloppy. Does a single die roll have one outcome or 6? -->
<p>Joint distributions are also mathematical objects that cover a set of outcomes, where each distinct outcome has a chance of occurring between 0 and 1 and the sum of all chances must equal 1. The key to a joint distribution is it measures the chance that both events A and B will occur. The notation is <span class="math inline">\(\text{Prob}(A, B)\)</span>.</p>
<p>Let’s say that you are rolling two six-sided dice simultaneously. Die 1 is weighted so that there is a 50% chance of rolling a 6 and a 10% chance of each of the other values. Die 2 is weighted so there is a 50% chance of rolling a 5 and a 10% chance of rolling each of the other values. Let’s roll both dice 1,000 times. In previous examples involving two dice, we cared about the sum of results and not the outcomes of the first versus the second die of each simulation. With a joint distributions, the order matters; so instead of 11 possible outcomes on the x-axis of our distribution plot (ranging from 2 to 12), we have 36. Furthermore, a 2D probability distribution is not sufficient to represent all of the variables involved, so the joint distribution for this example is displayed using a 3D plot.</p>
<div class="inline-figure"><img src="05-probability/images/joint.png" width="100%"></div>
</div>
</div>
<div id="tree-diagrams" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Tree diagrams<a class="anchor" aria-label="anchor" href="#tree-diagrams"><i class="fas fa-link"></i></a>
</h2>
<!-- DK: Worth rewriting? Yes! Tie it better to above and below. Not sure we even need tree diagrams. What are we trying to teach here? -->
<div id="independence" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Independence<a class="anchor" aria-label="anchor" href="#independence"><i class="fas fa-link"></i></a>
</h3>
<p>So far, you have learned how to explore <span class="math inline">\(\text{Prob}(A)\)</span>, which is the fancy, statistical way of saying the probability distribution for event A. Keep in mind the distinction between an individual outcome from the set <span class="math inline">\(A\)</span>, like the probability of heads (which is <span class="math inline">\(\rho_h\)</span>) and the entire distribution <span class="math inline">\(\text{Prob}(\text{coin})\)</span>, which includes the probability of each possible outcomes. <span class="math inline">\(\text{Prob}(A)\)</span> is like <span class="math inline">\(\text{Prob}(\text{coin})\)</span> or <span class="math inline">\(\text{Prob}(\text{sum of two dice})\)</span>.</p>
<p>What if you flipped two coins in a row, one after the other? You know that the probability of getting heads on the first coin is 1/2. But what are the odds of getting heads two times in a row? Let’s take a look at this tree diagram. We read this diagram from left to right. On the left, the probability of getting heads is 0.5 on the first toss. Then, the tree branches out.</p>
<ul>
<li>
<em>If</em> we got heads the first time, then we go up the top branch. The probability of getting heads again is 0.5.</li>
<li>
<em>If</em> we got tails the first time, then we go down the bottom branch. The probability of getting heads is 0.5.</li>
</ul>
<p>Notice how regardless of what we get the first time we flip the coin, the probability of getting heads is 0.5 throughout. Coin flips, in this scenario, are <strong>independent</strong>. The result of one coin flip does not impact the next coin flip.</p>
<!-- DK: Should we create these decision trees on the fly, perhaps using https://github.com/malcolmbarrett/ggdag  or maybe straight dagitty? For now, what we have is fine. -->
<div class="inline-figure"><img src="05-probability/images/tree-1.png" width="100%"></div>
</div>
<div id="conditional-probability" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Conditional probability<a class="anchor" aria-label="anchor" href="#conditional-probability"><i class="fas fa-link"></i></a>
</h3>
<p>Imagine that 60% of people in a community have a disease. A doctor develops a test to determine if a random person has the disease. However, this test isn’t 100% accurate. There is an 80% probability of correctly returning positive <strong>if the person has the disease</strong> and 90% probability of correctly returning negative <strong>if the person does not have the disease</strong>.</p>
<p>The probability of a random person having the disease is 0.6. Since each person either has the disease or doesn’t (those are the only two possibilities), the probability that a person does not have the disease is <span class="math inline">\(1 - 0.6 = 0.4\)</span>.</p>
<div class="inline-figure"><img src="05-probability/images/tree-2.png" width="100%"></div>
<p>Now the tree branches out.</p>
<ul>
<li>
<em>If</em> the random person has the disease, then we go up the top branch. The probability of an infected person testing positive is 0.8 because the test is 80% sure of correctly returning positive when the person has the disease.</li>
<li>By the same logic, <em>if</em> the random person does not have the disease, we go down the bottom branch. The probability of the person incorrectly testing positive is 0.1.</li>
</ul>
<p>We decide to go down the top branch <em>if</em> our random person has the disease. We go down the bottom branch <em>if</em> they do not. This is called <strong>conditional probability</strong>. The probability of testing positive is <strong>dependent</strong> on whether the person has the disease.</p>
<p>How would you express this in statistical notation? <span class="math inline">\(\text{Prob}(A|B)\)</span> is the same thing as the probability of A <em>given</em> B. <span class="math inline">\(\text{Prob}(A|B)\)</span> essentially means the probability of A <em>if</em> we know for sure the value of B. Note that <span class="math inline">\(\text{Prob}(A|B)\)</span> is not the same thing as <span class="math inline">\(\text{Prob}(B|A)\)</span>.</p>
<!-- DK: The above write up is not impressive. What are we trying to accomplish? Also, we might add some simple coding/simulation examples to illustrate these points.  -->
</div>
</div>
<div id="two-models" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Two models<a class="anchor" aria-label="anchor" href="#two-models"><i class="fas fa-link"></i></a>
</h2>
<p>You are in a city of 100,000 people. It is true that exactly 1% of the population has a disease, but we don’t know which people have it and which do not. In terms of a count, that means
1,000 people have this disease of the
100,000 in the population. We have a test which is 95% accurate. That is, if you have the disease there is a 95% chance that the test reports that you do, and the same if you don’t have the disease.</p>
<p>So, of the 1,000 people who truly do have the disease — where 1,000 is 1% of the
100,000 people in the city — 950 would correctly test positive and 50 would incorrectly test negative. The city also has 99,000 people who do not have the disease,<br>
4,950 of which incorrectly test positive and 94,050 of which correctly test negative. That means that the number of people who would test positive for the disease is 950 plus 4,950, which equals
5,900 but
<em>only 950 of them have the disease</em>. In simple terms, the probability of you having the disease <em>given a positive test result</em> is much lower than the stated 95% accuracy of the test.</p>
<p>Here is the joint empirical distribution of the test result and disease status. Note that this is an unnormalized distribution because each dot represents a person in this city.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-378-1.png" width="100%"></div>
<p>Here is a joint distribution displayed in 3D. Instead of using the “jitter” feature in R to unstack the dots, we are using a 3D plot to visualize the number of dots in each box. The number of people who correctly test negative in this city is 94,050, far outnumbering any of the other categories. There are 4,950 false positives, 950 true positives, and only 50 false negatives. This is why we can barely see the 3D bar coming from those combinations.</p>
<div class="inline-figure"><img src="05-probability/images/rayshader_disease.png" width="100%"></div>
<p>This section is called “Two Models” because, for each person, <em>there are two possible states of the world: have the disease or not have the disease.</em> By assumption, there are no other outcomes. We call these two possible states of the world “models,” even though they are very simple models.</p>
<p>In addition to the two models, we have two possible results of our experiment on a given person: test positive or test negative. Again, this is an assumption. We do not allow for any other outcome. In later sections, we will look at more complex situations where we consider more than two models and more than two possible results of the experiment. In the meantime, we have built the <em>unnormalized joint distribution for models and results</em>. This is a key point! Look back earlier in this chapter where we discussed both unnormalized distributions and joint distributions.</p>
<p>Getting back to the figure, what is the difference between these distributions? How can they be useful in data analysis?</p>
<p>We want to analyze these plots by looking at different slices. For instance, let’s say that you have tested positive for the disease. Since the test is not always accurate, you cannot be 100% certain that you have it. We would isolate the slice where the test result equals 1 (meaning positive). If we zoom in on the plot, 950 people who tested positive have the disease and 4,950 who tested positive do not have the disease. In this case, we are focusing on one slice of the probability distribution where the test result was positive. There are two disease outcomes: positive or negative. By isolating a section, we are looking at a conditional distribution. Conditional on a positive test, you can visualize the likelihood of actually having the disease versus not.</p>
<!-- This is what looks like when we take the slice where the test result is positive and zoom in. Taking a slice is the same thing as creating the conditional probability distribution. -->
<!-- ```{r, echo = FALSE} -->
<!-- knitr::include_graphics("05-probability/images/rayshader_disease_zoom.png") -->
<!-- ``` -->
<!-- We should rotate this slice and look at it from a 2D perspective. This looks very similar to what we saw at the beginning of the chapter when we flipped coins to create a probability distribution. -->
<!-- ```{r, echo = FALSE} -->
<!-- mydata <- tibble(results = c(rep(0, 5), -->
<!--                              rep(1, 5))) -->
<!-- ggplot(mydata, aes(x = results)) + -->
<!--   geom_histogram(aes(y = after_stat(count/sum(count))),  -->
<!--                  binwidth = 0.5,  -->
<!--                  color = "white") + -->
<!--   labs(title = "Conditional Probability Distribution", -->
<!--        subtitle = "Probability of Having the Disease Given a Positive Test Result", -->
<!--        x = "Disease Status", -->
<!--        y = "Probability") + -->
<!--   scale_x_continuous(breaks = c(0, 1),  -->
<!--                      labels = c("Positive", "Negative")) + -->
<!--   scale_y_continuous(labels =  -->
<!--                        scales::percent_format(accuracy = 1)) + -->
<!--   theme_classic() -->
<!-- ``` -->
<p>This Stat 110 Animations video does a really good job of explaining a similar concept.</p>
<iframe src="https://www.youtube.com/embed/by3_weGwnMg?showcase=0" width="100%" height="400px">
</iframe>
</div>
<div id="three-models" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Three models<a class="anchor" aria-label="anchor" href="#three-models"><i class="fas fa-link"></i></a>
</h2>
<!-- DK: Should this be in terms of p or number of white marbles or both? -->
<div class="inline-figure"><img src="05-probability/images/marble.jpg" width="100%"></div>
<p>Imagine that your friend gives you a bag with two marbles. There could either be two white marbles, two black marbles, or one of each color. Thus, the bag could contain 0% white marbles, 50% white marbles, or 100% white marbles. The proportion, <span class="math inline">\(p\)</span>, of white marbles could be 0, 0.5, or 1.</p>
<p>Let’s say you take a marble out of the bag, record whether it’s black or white, then return it to the bag. You repeat this three times, observing the number of white marbles you see out of three trials. You could get three whites, two whites, one white, or zero whites as a result of this trial. Let’s make what we call a Bayes scatterplot out of this. We have three models (three different proportions of white marbles in the bag) and four possible experimental results. Let’s create 3,000 draws from this joint distribution:</p>
<div class="sourceCode" id="cb533"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Create the joint distribution of the number of white marbles in the bag</span>
<span class="co"># (in_bag) and the number of white marbles pulled out in the sample (in_sample),</span>
<span class="co"># one-by-one. in_bag takes three possible values: 0, 1 and 2, corresponding to</span>
<span class="co"># zero, one and two white marbles potentially in the bag.</span>

<span class="va">joint_dist</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>in_bag <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fl">1000</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>in_sample <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">in_bag</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, 
                                              size <span class="op">=</span> <span class="fl">3</span>, 
                                              p <span class="op">=</span> <span class="va">.</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> 

<span class="va">joint_dist</span></code></pre></div>
<pre><code>## # A tibble: 3,000 x 2
##    in_bag in_sample
##     &lt;dbl&gt;     &lt;int&gt;
##  1      0         0
##  2      1         2
##  3      2         3
##  4      0         0
##  5      1         0
##  6      2         3
##  7      0         0
##  8      1         2
##  9      2         3
## 10      0         0
## # … with 2,990 more rows</code></pre>
<p>Plot the joint distribution:</p>
<!-- DK: More clean up. Work with in_bag and in_sample -->
<div class="sourceCode" id="cb535"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># The distribution is unnormalized. All we see is the number of simulations in</span>
<span class="co"># each "bucket."</span>

<span class="va">joint_dist</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">in_sample</span>, y <span class="op">=</span> <span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_jitter</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Black and White Marbles"</span>,
         subtitle <span class="op">=</span> <span class="st">"More white marbles in bag mean more white marbles selected"</span>,
         x <span class="op">=</span> <span class="st">"White Marbles Selected"</span>,
         y <span class="op">=</span> <span class="st">"White Marbles in the Bag"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-383-1.png" width="100%"></div>
<p>Here is the 3D visualization:</p>
<div class="inline-figure"><img src="05-probability/images/three_models.png" width="100%"></div>
<p>The y-axes of both the scatterplot and the 3D visualization are labeled “Number of White Marbles in the Bag.” Each value on the y-axis is a model, a belief about the world. For instance, when the model is 0, we have no white marbles in the bag, meaning that none of the marbles we pull out in the sample will be white.</p>
<p>Let’s say draw out three white marbles. We isolate the slice where the result of the simulation involves three white marbles and zero black ones. Here is the unnormalized probability distribution.</p>
<div class="sourceCode" id="cb536"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># The key step is the filter. Creating a conditional distribution from a joint</span>
<span class="co"># distribution is the same thing as filtering that joint distribution for a</span>
<span class="co"># specific value. A conditional distribution is a "slice" of the joint</span>
<span class="co"># distribution, and we take that slice with filter().</span>

<span class="va">joint_dist</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">in_sample</span> <span class="op">==</span> <span class="fl">3</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.25</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Unnormalized Conditional Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of white marbles in bag given that three were selected in the sample"</span>,
         x <span class="op">=</span> <span class="st">"Number of White Marbles in the Bag"</span>,
         y <span class="op">=</span> <span class="st">"Count"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-385-1.png" width="100%"></div>
<p>Next, let’s normalize the distribution.</p>
<div class="sourceCode" id="cb537"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">joint_dist</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">in_sample</span> <span class="op">==</span> <span class="fl">3</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_histogram</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu">after_stat</span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, 
                   binwidth <span class="op">=</span> <span class="fl">0.25</span>, 
                   color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of white marbles in bag given that three were selected in the sample"</span>,
         x <span class="op">=</span> <span class="st">"Number of White Marbles in the Bag"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> 
                         <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org//reference/label_percent.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-386-1.png" width="100%"></div>
<p>This plot makes sense because when all three marbles you draw out of the bag are white, there is a pretty good chance that there are no black marbles in the bag. But you can’t be certain! It is possible to draw three white even if the bag contains one white and one black. Yes, about 10%. However, it is impossible that there are no white marbles in the bag.</p>
<!-- DK: Maybe we should plot 0% over 0 white marbles. -->
</div>
<div id="n-models" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> N models<a class="anchor" aria-label="anchor" href="#n-models"><i class="fas fa-link"></i></a>
</h2>
<!-- 5 a) Now go on to Rethinking approach. I think that chapter 2 is just genius. Bayesian is really just counting. Maybe we do a very similar example to what he does? Maybe different? I am still pondering this myself. I think that there is a deep relationship here. In the simple Bayes rule decision trees, we know all the probabilities. But what if we don't? Instead, we get to observe lots of data (which are counts!) and then, from that data, figure out the probabilities. (Note that Rethinking does not talk like this --- after all, we know all the probabilities since each marble has a 20% chance of being drawn --- but I think it is implicit in his approach.) Key issue: Can we connect this in a sensible way to Bayesian scatterplot. There is always the data and the model and the relationship between the two. (And "the model" means, mainly, the parameter estimates thereof.) Tell me the data, and I will tell you the model. Tell me the model, and I will tell you the model. -->
<!-- Note the connection between the marbles from Rethinking and the Bayesian scatterplot. In figure 2.2 in Rethinking represents the model where p = 0.25, where p is the proportion of blue marbles in the total collection. The y-axis models would be labeled with p = 0, 0.25, 0.5, 0.75, and 1. With the tree marble diagram in figure 2.2, we would be taking random samples with 3 marbles. The number of blue marbles we get each time would be plotted along p = 0.25. This is another example of model on the y-axis and data on the x-axis. -->
<!-- DK: Should we cut out p = 0 and p = 1 as too annoying to deal with? -->
<div class="inline-figure"><img src="05-probability/images/heads.jpg" width="100%"></div>
<p>Assume that there is a coin with <span class="math inline">\(\rho_h\)</span>. We guarantee that there are only 11 possible values of <span class="math inline">\(\rho_h\)</span>: <span class="math inline">\(0, 0.1, 0.2, ..., 0.9, 1\)</span>. In other words, there are 11 possible models, 11 things which might be true about the world. This is just like situations we have previously discussed, except that there are more models to consider.</p>
<p>We are going to run an experiment in which you flip the coin 20 times and record the number of heads. What does this result tell you about the value of <span class="math inline">\(\rho_h\)</span>? Ultimately, we will want to calculate a posterior distribution of <span class="math inline">\(\rho_h\)</span>, which is written as p(<span class="math inline">\(\rho_h\)</span>).</p>
<p>To start, it is useful to consider all the things which might happen if, for example, <span class="math inline">\(\rho_h = 0.4\)</span>. Fortunately, the R functions for simulating random variables makes this easy.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-388-1.png" width="100%"></div>
<p>First, notice that many different things can happen! Even if we <em>know</em>, for certain, that <span class="math inline">\(\rho_h = 0.4\)</span>, many outcomes are possible. Life is remarkably random. Second, the most likely result of the experiment is 8 heads, as we would expect. Third, we have transformed the raw counts of how many times each total appeared into a probability distribution. Sometimes, however, it is convenient to just keep track of the raw counts. The shape of the figure is the same in both cases.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-389-1.png" width="100%"></div>
<p>Either way, the figures show what would have happened if that model — that <span class="math inline">\(\rho_h = 0.4\)</span> — were true.</p>
<p>We can do the same thing for all 11 possible models, calculating what would happen if each of them were true. This is somewhat counterfactual since only one of them can be true. Yet this assumption does allow us to create the <em>joint distribution</em> of <em>models which might be true</em> and of <em>data which our experiment might generate</em>. Let’s simplify this is p(models, data), although you should keep the precise meaning in mind.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-390-1.png" width="100%"></div>
<p>Here is the 3D version of the same plot.</p>
<div class="inline-figure"><img src="05-probability/images/n_models.png" width="100%"></div>
<p>In both of these diagrams, we see 11 models and 21 outcomes. We don’t really care about the p(<span class="math inline">\(models\)</span>, <span class="math inline">\(data\)</span>), the joint distribution of the models-which-might-be-true and the data-which-our-experiment-might-generate. Instead, we want to estimate <span class="math inline">\(p\)</span>, the unknown parameter which determines the probability that this coin will come up heads when tossed. The joint distribution alone can’t tell us that. We <em>created</em> the joint distribution before we had even conducted the experiment. It is our creation, a tool which we use to make inferences. Instead, we want the conditional distribution, p(<span class="math inline">\(models\)</span> | <span class="math inline">\(data = 8\)</span>). We have the results of the experiment. What do those results tell us about the probability distribution of <span class="math inline">\(p\)</span>?</p>
<p>To answer this question, we simply take a vertical <em>slice</em> from the joint distribution at the point of the x-axis corresponding to the results of the experiment.</p>
<p>This animation shows what we want to do with joint distributions. We take a slice (the red one), isolate it, rotate it to look at the conditional distribution, normalize it (change the values along the current z-axis from counts to probabilities), then observe the resulting posterior.</p>
<div class="inline-figure"><img src="05-probability/animations/color_red_combo.gif"></div>
<p>This is the only part of the joint distribution that we care about. We aren’t interested in what the object looks like where, for example, the number of heads is 11. That portion is irrelevant because we observed 8 heads, not 11. By using the filter function on the simulation tibble we created, we can conclude that there are a total of 465 times in our simulation in which 8 heads were observed.</p>
<p>As we would expect, most of the time when 8 coin tosses came up heads, the value of <span class="math inline">\(p\)</span> was 0.4. But, on numerous occasions, it was not. It is quite common for a value of <span class="math inline">\(p\)</span> like 0.3 or 0.5 to generate 8 heads. Consider:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-392-1.png" width="100%"></div>
<p>Yet this is a distribution of raw counts. It is an unnormalized density. To turn it into a proper probability density (i.e., one in which the sum of the probabilities across possible outcomes sums to one) we just divide everything by the total number of observations.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-393-1.png" width="100%"></div>
<p>The most likely value of <span class="math inline">\(\rho_h\)</span> is still 0.4, as before. But, it is much more likely that <span class="math inline">\(p\)</span> is either 0.3 or 0.5. And there is about an 8% chance that <span class="math inline">\(\rho_h \ge 0.6\)</span>.</p>
<p>You might be wondering: what is the use of a model? Well, let’s say we toss the coin 20 times and get 8 heads again. Given this result, what is the probability that future samples of 20 flips will result in 10 or more heads?</p>
<p>There are three main ways you could go about solving this problem with simulations.</p>
<p>The first <em>wrong</em> way to do this is assuming that <span class="math inline">\(\rho_h\)</span> is certain because we observed 8 heads after 20 tosses. We would conclude that 8/20 gives us 0.4. The big problem with this is that you are ignoring your uncertainty when estimating <span class="math inline">\(\rho_h\)</span>. This would lead us to the following code.</p>
<div class="sourceCode" id="cb538"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sims</span> <span class="op">&lt;-</span> <span class="fl">10000000</span>

<span class="va">odds</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>sim_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">sims</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">sim_ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="fl">.4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>result <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">&gt;=</span> <span class="fl">10</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span><span class="op">/</span><span class="va">sims</span><span class="op">)</span>

<span class="va">odds</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   success
##     &lt;dbl&gt;
## 1   0.245</code></pre>
<p>The second method involves sampling the whole posterior distribution vector we previously created. This would lead to the following correct code.</p>
<div class="sourceCode" id="cb540"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_draws</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.1</span><span class="op">)</span>, <span class="fl">1000</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">p</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span>
  
<span class="va">odds</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_draws</span><span class="op">$</span><span class="va">p</span>, size <span class="op">=</span> <span class="va">sims</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">p</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>result <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">&gt;=</span> <span class="fl">10</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span><span class="op">/</span><span class="va">sims</span><span class="op">)</span>

<span class="va">odds</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   success
##     &lt;dbl&gt;
## 1   0.328</code></pre>
<p>Third way is to sample from the actual distribution, which is a small dataset with just a few rows, but it includes both <span class="math inline">\(\rho_h\)</span> and the probability of each <span class="math inline">\(\rho_h\)</span>. This also gives the correct answer.</p>
<div class="sourceCode" id="cb542"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_posterior</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>total <span class="op">=</span> <span class="fu">n</span><span class="op">(</span><span class="op">)</span>, .groups <span class="op">=</span> <span class="st">"drop"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>probs <span class="op">=</span> <span class="va">total</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">total</span><span class="op">)</span><span class="op">)</span>

<span class="va">odds</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_posterior</span><span class="op">$</span><span class="va">p</span>, 
                          size <span class="op">=</span> <span class="va">sims</span>, 
                          prob <span class="op">=</span> <span class="va">p_posterior</span><span class="op">$</span><span class="va">probs</span>, 
                          replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu">map_int</span><span class="op">(</span><span class="va">p</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, 
                                     size <span class="op">=</span> <span class="fl">20</span>, 
                                     p <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>result <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">&gt;=</span> <span class="fl">10</span>, 
                         <span class="cn">TRUE</span>, 
                         <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span><span class="op">/</span><span class="va">sims</span><span class="op">)</span>

<span class="va">odds</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   success
##     &lt;dbl&gt;
## 1   0.320</code></pre>
<p>As you may have noticed, if you calculated the value using the first method, you would believe that getting 10 or more heads is less likely than it really is. If you were to run a casino based on these assumptions, you will lose all your money. It is very important to be careful about the assumptions you are making. We tossed a coin 20 times and got 8 heads. However, you would be wrong to assume that <span class="math inline">\(\rho_h\)</span> = 0.4 just based on this result.</p>
<!-- ## Testing is evil -->
<!-- Introduce concepts like the null model, testing, and p-values. Connect to permutation tests from chapter 3.  Side note quotation: "Amateurs test. Professionals summarize." Maybe we should pick an example in which the number of heads is low enough to provide some reasonable evidence against p = 0.5. -->
<!-- In some fields, it is common to want to test a specific hypothesis. Consider the hypothesis that the coin is fair, i.e., that $p = 0.5$. Does the data we have support or reject that hypothesis? (Be wary that $p$ is both used for the probability of a head and the $p$-value of a hypothesis test.) -->
<!-- Not really interested in that exact test except in toy scenarios. -->
<!-- Difference between 0.04 and 0.06 is rarely significant. And is hardly ever a good reason to decide X over Y. -->
</div>
<div id="cardinal-virtues" class="section level2" number="5.6">
<h2>
<span class="header-section-number">5.6</span> Cardinal Virtues<a class="anchor" aria-label="anchor" href="#cardinal-virtues"><i class="fas fa-link"></i></a>
</h2>
<p>The four <a href="https://en.wikipedia.org/wiki/Cardinal_virtues">Cardinal Virtues</a> are Wisdom, Justice, Courage, and Temperance. Because data science is, ultimately, a moral act, we use these virtues to guide our work. <em>Wisdom</em> highlights the importance of exploring your data. Given the questions you seek to answer, is the data valid? Is it representative? Is it ethical to proceed? <em>Justice</em> focuses on the Preceptor Table and the mathematical structure of the model. The virtue of <em>Courage</em> allows us to go from words and math to code, the hardest step in the data science process. <em>Temperance</em> guides us in the use of the model we have created to answer the questions we began with. We should be modest in the claims we make, and wary of naive attempts to “test” them.</p>
<!-- DK: THe below Not bad, but should be rewritten and tightened up. Delete the themes.Rmd when you are done. If it is worth remembering, it is worth including here. Highlight these two key connections: validity <==> columns and representativeness <==> rows. -->
<div id="wisdom" class="section level3" number="5.6.1">
<h3>
<span class="header-section-number">5.6.1</span> Wisdom<a class="anchor" aria-label="anchor" href="#wisdom"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-397"></span>
<img src="other/images/Wisdom.jpg" alt="Wisdom." width="100%"><p class="caption">
FIGURE 5.4: Wisdom.
</p>
</div>
<p>Wisdom encompasses four topics: data, validity, , the population and ethics.</p>
<p>First, we look at the data and perform an exploratory data analysis, an EDA. You can never look at your data too much.</p>
<p>Second, confirm that the data we have accurately capturing the concepts we care about. <span class="citation"><a href="references.html#ref-roas" role="doc-biblioref">Gelman, Hill, and Vehtari</a> (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span> write:</p>
<blockquote>
<p>Most important is that the data you are analyzing should map to the research question you are trying to answer. This sounds obvious but is often overlooked or ignored because it can be inconvenient. Optimally, this means that the outcome measure should accurately reflect the phenomenon of interest, the model should include all relevant predictors, and the model should generalize to the cases to which it will be applied.</p>
</blockquote>
<blockquote>
<p>For example, with regard to the outcome variable, a model of incomes will not necessarily tell you about patterns of total assets. A model of test scores will not necessarily tell you about child intelligence or cognitive development. …</p>
</blockquote>
<blockquote>
<p>A sample that is representative of all mothers and children may not be the most appropriate for making inferences about mothers and children who participate in the Temporary Assistance for Needy Families program. … Similarly, results regarding diet and exercise obtained from a study performed on patients at risk for heart disease may not be generally applicable to generally healthy individuals.</p>
</blockquote>
<p>We want there to be a connection between the problem we face and the data we have. But desire is a poor replacement for substance. If the data we have is not relevant, then data science is useless.</p>
<p>Third, a key concept is the “population,” which is largely equivalent to the rows of the ideal Preceptor Table, as discussed in Chapter <a href="rubin-causal-model.html#rubin-causal-model">4</a>. <span class="citation"><a href="references.html#ref-roas" role="doc-biblioref">Gelman, Hill, and Vehtari</a> (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span> write:</p>
<!-- DK: This is not bad, but needs to be re-written. -->
<blockquote>
<p>A regression model is fit to data and is used to make inferences about a larger population, hence the implicit assumption in interpreting regression coefficients is that the sample is representative of the population.</p>
</blockquote>
<blockquote>
<p>To be more precise, the key assumption is that the data are representative of the distribution of the outcome <span class="math inline">\(y\)</span> given the predictors <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, …, that are included in the model. For example, in a regression of earnings on height and sex, it would be acceptable for women and tall people to be overrepresented in the sample, compared to the general population, but problems would arise if the sample includes too many rich people. Selection on x does not interfere with inferences from the regression model, but selection on y does. This is one motivation to include more predictors in our regressions, to allow the assumption of representativeness, conditional on X, to be more reasonable.</p>
</blockquote>
<blockquote>
<p>Representativeness is a concern even with data that would not conventionally be considered as a sample. For example, the forecasting model in Section 7.1 contains data from 16 consecutive elections, and these are not a sample from anything, but one purpose of the model is to predict future elections. Using the regression fit to past data to predict the next election is mathematically equivalent to considering the observed data and the new outcome as a random sample from a hypothetical superpopulation. Or, to be more precise, it is like treating the errors as a random sample from the normal error distribution. For another example, if a regression model is fit to data from the 50 states, we are not interested in making predictions for a hypothetical 51st state, but you may well be interested in the hypothetical outcome in the 50 states in a future year. As long as some generalization is involved, ideas of statistical sampling arise, and we need to think about representativeness of the sample to the implicit or explicit population about which inferences will be drawn. This is related to the idea of generative modeling, as discussed in Section 4.1.</p>
</blockquote>
<p>Validity is about the columns in our tibble. Representativeness is about the rows.</p>
<p>Fourth, even if we can make a model, we should always ask ourselves: Should we? Ethics matter.</p>
</div>
<div id="justice" class="section level3" number="5.6.2">
<h3>
<span class="header-section-number">5.6.2</span> Justice<a class="anchor" aria-label="anchor" href="#justice"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-398"></span>
<img src="other/images/Justice.jpg" alt="Justice." width="100%"><p class="caption">
FIGURE 5.5: Justice.
</p>
</div>
<p>There are three key aspects of <em>Justice</em>: the Preceptor Table, predictive versus causal models, and mathematical formula.</p>
<div id="preceptor-table" class="section level4" number="5.6.2.1">
<h4>
<span class="header-section-number">5.6.2.1</span> Preceptor Table<a class="anchor" aria-label="anchor" href="#preceptor-table"><i class="fas fa-link"></i></a>
</h4>
<!-- DK: Could have more here. -->
<p>Precision matters. What do you know and what do you want to know? Creating a Preceptor Table forces you to be clear about what you are trying to accomplish and the problems you will face along the way.</p>
<p><strong>A Preceptor Table is a table with rows and columns for all the data that we have and would (reasonably) like to have.</strong> If we had a Preceptor Table with no questions marks — which we describe below as the ideal Preceptor Table — we could calculate the number we want without the need for any inference.</p>
<p>First, the infinite Preceptor Table is well described in Chapter <a href="rubin-causal-model.html#rubin-causal-model">4</a>. We never use these, but it useful to understand them, and the assumptions we must make to work with something simpler.</p>
<p>Second, the ideal Preceptor Table is the Preceptor Table with no question marks, and with a reasonable number of rows and columns. Conceptually, this is the heart of the analysis.</p>
<p>Third, the actual Preceptor Table is the Preceptor Table with all the annoying question marks which the real world saddles us with.</p>
<p>The central problem in inference is to fill in the question marks on the actual Preceptor Table.</p>
<p>Note that the concept of a Preceptor Table is more subtle than it at first appears. For example, consider a problem in which we are using <code>party</code> to predict <code>income</code> with the <code>trains</code> data. Naively, it might look like we don’t have any question marks. For all 115 rows in the data, we have <code>party</code> and <code>income</code>. But the Preceptor Table we really need has more than 115 rows because we are trying to draw inferences about people not in the sample of 115. What if a new person shows up, tells us their party, and asks us to guess their income? The ideal Preceptor Table would include their row, with the data for <code>party</code> present but the data for <code>income</code> a question mark.</p>
</div>
<div id="predictive-versus-causal-models" class="section level4" number="5.6.2.2">
<h4>
<span class="header-section-number">5.6.2.2</span> Predictive versus causal models<a class="anchor" aria-label="anchor" href="#predictive-versus-causal-models"><i class="fas fa-link"></i></a>
</h4>
<p>Are we are modeling (just) for prediction or are we (also) modeling for causation? Predictive models care nothing about causation. Causal models are often also concerned with prediction, if only as a means of measuring the quality of the model.</p>
<p>Every model is predictive, in the sense that, if we give you new data — and it is drawn from a stable distribution — then you can create a predictive forecast. But only a subset of those models are causal, meaning that, for a given individual, you can change the value of one input and figure out what the new output would be and then, from that, calculate the causal effect.</p>
<p>With prediction, all we care about is forecasting Y given X on some as-yet-unseen data — implying that the Preceptor Table has rows in which we know all the X but not the Y. But there is no notion of “manipulation” in such models. We don’t pretend that, for Joe, we could turn variable X from a value of 5 to a value of 30 by just turning some knob and, by doing so, cause Joe’s value of Y to change from 17 to 23. We can compare two people (or two groups of people), one with X equal to 5 and one with X equal to 30, and see how they differ in Y. The basic assumption of predictive models is that there is only one possible Y for Joe. There are not, by assumption, two possible values for Y, one if X equal 5 and another if X equals 30. The Preceptor Table has a single column under Y.</p>
<p>With causal inference, however, we can consider the case of Joe with <span class="math inline">\(X = 5\)</span> and Joe with <span class="math inline">\(X = 30\)</span>. The same mathematical model can be used. And both models can be used for prediction, for estimating what the value of Y will be for a yet-unseen observation with values X. But, in this case, instead of only a single column in the Preceptor Table for Y, we have at least two (and possibly many) such columns, one for each of the potential outcomes under consideration.</p>
<p><em>The difference between prediction models and causal models is that the former have one column for Y and the latter have more than one.</em></p>
<p>A related issue is the different types of Preceptor Tables. All of these are Preceptor Tables, but it is useful, I think, to have a clear description of the different types.</p>
</div>
<div id="mathematical-model" class="section level4" number="5.6.2.3">
<h4>
<span class="header-section-number">5.6.2.3</span> Mathematical Model<a class="anchor" aria-label="anchor" href="#mathematical-model"><i class="fas fa-link"></i></a>
</h4>
<p><em>Justice</em> requires (simple) math. Consider a model of coin-tossing:</p>
<p><span class="math display">\[ T_i  \sim B(p_H, n = 20) \]</span>
The total number <span class="math inline">\(T\)</span> of Heads in experiment <span class="math inline">\(i\)</span> with 20 flips of a single coin, <span class="math inline">\(T_i\)</span>, is distributed as a binomial with <span class="math inline">\(n = 20\)</span> and an unknown probability <span class="math inline">\(\rho_h\)</span> of the coin coming up Heads.</p>
<p>Note:</p>
<ul>
<li><p>This is a cheat and a simplification! We are Bayesians but we have not specified the full Bayesian machinery. We really need priors on the unknown parameter <span class="math inline">\(\rho_h\)</span> as well. But that is too complex for an introductory class, so we wave our hands, accept the default sesinvle parameters built into the functions we use and point readers to more advanced books, like <span class="citation"><a href="references.html#ref-roas" role="doc-biblioref">Gelman, Hill, and Vehtari</a> (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span>.</p></li>
<li><p>Defining <span class="math inline">\(\rho_h\)</span> as the “the probability that the coin comes up Heads” is a bit of a fudge. If you calculate that by hand and then compare it to what our tools produce, they won’t be the same. Instead, the calculated value will be closer to zero. Why? <span class="math inline">\(\rho_h\)</span> is really the “long-run percentage of the time the coin comes up Heads.” It is not just the percentage from this experiment.</p></li>
</ul>
<!-- DK: too complex for this chapter? --><ul>
<li>In this simple case, we are fortunate that the parameter <span class="math inline">\(\rho_h\)</span> has such a (mostly!) simple analog to a real world quantity. Much of the time, parameters are not so easy to interpret. In a more complex model, especially with one with interaction terms, we focus less on parameters and more on actual predictions.</li>
</ul>
</div>
</div>
<div id="courage" class="section level3" number="5.6.3">
<h3>
<span class="header-section-number">5.6.3</span> Courage<a class="anchor" aria-label="anchor" href="#courage"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-399"></span>
<img src="other/images/Courage.jpg" alt="Courage." width="100%"><p class="caption">
FIGURE 5.6: Courage.
</p>
</div>
<p>The three languages of data science are words, math and code, and the most important of these is code. We need to explain the structure of our model using all three languages, but we need <em>Courage</em> to implement the model in code.</p>
<p>Code allows us to “fit” a model by estimating the values of the unknown parameters, like <span class="math inline">\(\rho_h\)</span>. Sadly, we can never know the true values of these parameters. But, like all good data scientists, we can express our uncertain knowledge in the form of posterior probability distributions. With those distributions, we can compare the actual values of the outcome variable with the “fitted” or “predicted” results of the model. We can examine the “residuals,” the difference between the fitted and actual values.</p>
<p>Every outcome is the sum of two parts: the model and what is not in the model:</p>
<p><span class="math display">\[outcome = model + what\ is\ not\ in\ the\ model\]</span></p>
<p>It doesn’t matter what the outcome is. It could be the result of a coin flip, the weight of a person, the GDP of a country. Whatever <em>outcome</em> we are considering is always made up of two parts. The first is the model we have created. The second is all the stuff — all the blooming and buzzing complexity of the real world — which is not a part of the model.</p>
<p>Some of our uncertainty is driven by our ignorance about <span class="math inline">\(\rho_h\)</span>.</p>
<p>A parameter is something which does not exist in the real world. (If it did, or could, then it would be data.) Instead, a parameter is a mental abstraction, a building block which we will use to to help us accomplish our true goal: To replace at least some of the questions marks in the Preceptor Table. Since parameters are mental abstractions, we will always be uncertain as to their value, however much data we might collect.</p>
<p>But some, often most, of the uncertainty comes from forces that are, by assumption, not in the model. For example, if the coin is fair, we expect <span class="math inline">\(T_i\)</span> to equal 10. But, often, it will be different, even if we are correct and <span class="math inline">\(\rho_h\)</span> equals exactly 0.5. <em>Some randomness is intrinsic in this fallen world.</em></p>
</div>
<div id="temperance" class="section level3" number="5.6.4">
<h3>
<span class="header-section-number">5.6.4</span> Temperance<a class="anchor" aria-label="anchor" href="#temperance"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span id="fig:unnamed-chunk-400"></span>
<img src="other/images/Temperance.jpg" alt="Temperance." width="100%"><p class="caption">
FIGURE 5.7: Temperance.
</p>
</div>
<p>There are few more important concepts in statistics and data science than the “Data Generating Mechanism.” Our <em>data</em> — the data that we collect and see — has been <em>generated</em> by the complexity and confusion of the world. God’s own <em>mechanism</em> has brought His data to us. Our job is to build a model of that process, to create, on the computer, a mechanism which generates fake data consistent with the data which we see. With that DGM, we can answer any question which we might have. In particular, with the DGM, we provide predictions of data we have not seen and estimates of the uncertainty associated with those predictions. <em>Courage</em> helped us to create the DGM. <em>Temperance</em> will guide us in its use.</p>
<p>Having created (and checked) a model, we now use the model to answer questions. Models are made for use, not for beauty. The world confronts us. Make decisions we must. Our decisions will be better ones if we use high quality models to help make them.</p>
<p>Sadly, our models are never as good as we would like them to be. First, the world is intrinsically uncertain.</p>
<div class="figure">
<span id="fig:unnamed-chunk-401"></span>
<img src="05-probability/images/donald_rumsfeld.jpg" alt="Donald Rumsfeld." width="100%"><p class="caption">
FIGURE 5.8: Donald Rumsfeld.
</p>
</div>
<blockquote>
<p>There are known knowns. There are things we know we know. We also know there are known unknowns. That is to say, we know there are some things we do not know. But there are also unknown unknowns, the ones we do not know we do not know. – Donald Rumsfeld</p>
</blockquote>
<p>What we really care about is data we haven’t seen yet, mostly data from tomorrow. But what if the world changes, as it always does? If it doesn’t change much, maybe we are OK. If it changes a lot, then what good will our model be? In general, the world changes some. That means that are forecasts are more uncertain that a naive use of our model might suggest.</p>
<div class="figure">
<span id="fig:unnamed-chunk-402"></span>
<img src="05-probability/images/Three_Card_Monte.jpg" alt="Three Card Monte." width="100%"><p class="caption">
FIGURE 5.9: Three Card Monte.
</p>
</div>
<p>What does this mean? Well imagine a crowd playing Three Card Monte in the streets of New York. The guy running the game runs a demo and shows you all the cards to make you confident. They earn money by making you overconfident and persuading you to bet. Your odds may seem good during the demo round, but that doesn’t actually say anything about what will likely happen when the real, high stakes game begins. The person running the game does many simulations, making the “victim” forget that they cannot actually make any conclusions about the odds of winning. There are some variables that we simply do not know even if we put a lot of effort into making posterior probability distributions. People can be using slight of hand, for instance.</p>
<p>We need patience in order to study and understand the unknown unknowns in our data. Patience is also important when we analyze the “realism” of our models. When we created the mathematical probability distribution for presidential elections, for instance, we assumed that the Democratic candidate would have a 50% chance of winning each vote in the electoral college. By comparing the mathematical model to our empirical cases, however, we recognize that the mathematical model is unlikely to be true. The mathematical model suggested that getting fewer than 100 votes is next to impossible, but many past Democratic candidates in the empirical distribution received less than 100 electoral votes.</p>
<!-- DK: Could do more here. Show the iterative process of model building, including posterior predictive checks. -->
<!-- Null hypothesis testing is a mistake. There is only the data, the models and the summaries therefrom. Describe an hypothesis test each chapter, and then dismiss it. Play the prediction game. That, perhaps, provides a useful framework for why NHST is stupid. Or, rather, you play the prediction game to figure out which statistical procedures are best --- and or, how well procedure X works --- and then use that information to make a decision. Explain what a test is, and why we think it is a waste of time to do them, and why people do them anyway. Key issue: If p = 0.04 really makes you do something totally different than p = 0.06, then either you (or the system within which you are operating) is stupid. -->
</div>
</div>
<div id="summary-5" class="section level2" number="5.7">
<h2>
<span class="header-section-number">5.7</span> Summary<a class="anchor" aria-label="anchor" href="#summary-5"><i class="fas fa-link"></i></a>
</h2>
<!-- DK: Not a bad summary, but should hit the key points more clearly.  -->
<p>Throughout this chapter, we spent time going through examples of conditional distributions. However, it’s worth noting that all probability distributions are conditional on something. Even in the most simple examples, when we were flipping a coin multiple times, we were assuming that the probability of getting heads versus tails did not change between tosses.</p>
<p>We also discussed the difference between empirical, mathematical, and posterior probability distributions. Even though we developed these heuristics to better understand distributions, every time we make a claim about the world, it is based on our beliefs - what we think about the world. We could be wrong. Our beliefs can differ. Two reasonable people can have conflicting beliefs about the fairness of a die.</p>
<p>It is useful to understand the three types of distributions and the concept of conditional distributions, but almost every probability distribution is conditional and posterior. We can leave out both words in future discussions, as we generally will in this book. They are implicit.</p>
<p>If you are keen to learn more about probability, here is a video featuring Professor Gary King. This is a great way to review some of the concepts we covered in this chapter, albeit at a higher level of mathematics.</p>
<iframe src="https://www.youtube.com/embed/6C7yRBfh2ok?showcase=0" width="100%" height="400px">
</iframe>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></div>
<div class="next"><a href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#probability"><span class="header-section-number">5</span> Probability</a></li>
<li>
<a class="nav-link" href="#probability-distributions"><span class="header-section-number">5.1</span> Probability distributions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#flipping-a-coin"><span class="header-section-number">5.1.1</span> Flipping a coin</a></li>
<li><a class="nav-link" href="#rolling-two-dice"><span class="header-section-number">5.1.2</span> Rolling two dice</a></li>
<li><a class="nav-link" href="#presidential-elections"><span class="header-section-number">5.1.3</span> Presidential elections</a></li>
<li><a class="nav-link" href="#continuous-distributions"><span class="header-section-number">5.1.4</span> Continuous distributions</a></li>
<li><a class="nav-link" href="#working-with-probability-distributions"><span class="header-section-number">5.1.5</span> Working with probability distributions</a></li>
<li><a class="nav-link" href="#unnormalized-distributions"><span class="header-section-number">5.1.6</span> Unnormalized distributions</a></li>
<li><a class="nav-link" href="#joint-distributions"><span class="header-section-number">5.1.7</span> Joint distributions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tree-diagrams"><span class="header-section-number">5.2</span> Tree diagrams</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#independence"><span class="header-section-number">5.2.1</span> Independence</a></li>
<li><a class="nav-link" href="#conditional-probability"><span class="header-section-number">5.2.2</span> Conditional probability</a></li>
</ul>
</li>
<li><a class="nav-link" href="#two-models"><span class="header-section-number">5.3</span> Two models</a></li>
<li><a class="nav-link" href="#three-models"><span class="header-section-number">5.4</span> Three models</a></li>
<li><a class="nav-link" href="#n-models"><span class="header-section-number">5.5</span> N models</a></li>
<li>
<a class="nav-link" href="#cardinal-virtues"><span class="header-section-number">5.6</span> Cardinal Virtues</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wisdom"><span class="header-section-number">5.6.1</span> Wisdom</a></li>
<li><a class="nav-link" href="#justice"><span class="header-section-number">5.6.2</span> Justice</a></li>
<li><a class="nav-link" href="#courage"><span class="header-section-number">5.6.3</span> Courage</a></li>
<li><a class="nav-link" href="#temperance"><span class="header-section-number">5.6.4</span> Temperance</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-5"><span class="header-section-number">5.7</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PPBDS/primer/blob/master/05-probability.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PPBDS/primer/edit/master/05-probability.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Preceptor’s Primer for Bayesian Big Data Science</strong>" was written by David Kane. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
