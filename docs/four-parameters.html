<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Four Parameters | Preceptor’s Primer for Bayesian Data Science</title>
<meta name="author" content="David Kane">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.5.3/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script><script src="libs/plotly-binding-4.9.2.1/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet">
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script><script src="libs/rglWebGL-binding-0.103.5/rglWebGL.js"></script><link href="libs/rglwidgetClass-0.103.5/rgl.css" rel="stylesheet">
<script src="libs/rglwidgetClass-0.103.5/rglClass.min.js"></script><script src="libs/CanvasMatrix4-0.103.5/CanvasMatrix.min.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Preceptor’s Primer for Bayesian Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preamble.html">Preamble</a></li>
<li><a class="" href="shopping-week.html">Shopping Week</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">1</span> Visualization</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">2</span> Wrangling</a></li>
<li><a class="" href="functions.html"><span class="header-section-number">3</span> Functions</a></li>
<li><a class="" href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></li>
<li><a class="" href="probability.html"><span class="header-section-number">5</span> Probability</a></li>
<li><a class="" href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></li>
<li><a class="" href="two-parameters.html"><span class="header-section-number">7</span> Two Parameters</a></li>
<li><a class="" href="three-parameters.html"><span class="header-section-number">8</span> Three Parameters</a></li>
<li><a class="active" href="four-parameters.html"><span class="header-section-number">9</span> Four Parameters</a></li>
<li><a class="" href="five-parameters.html"><span class="header-section-number">10</span> Five Parameters</a></li>
<li><a class="" href="n-parameters.html"><span class="header-section-number">11</span> N Parameters</a></li>
<li><a class="" href="case-studies.html"><span class="header-section-number">12</span> Case Studies</a></li>
<li><a class="" href="tools.html">Tools</a></li>
<li><a class="" href="shiny.html">Shiny</a></li>
<li><a class="" href="maps.html">Maps</a></li>
<li><a class="" href="ipums.html">IPUMS</a></li>
<li><a class="" href="animation.html">Animation</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PPBDS/primer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="four-parameters" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Four Parameters<a class="anchor" aria-label="anchor" href="#four-parameters"><i class="fas fa-link"></i></a>
</h1>
<!-- Models are often similar. -->
<!-- Explore causal effects of models following chapter 18/19 in ROAS. Regress ending att on starting attitude and treatment effect. Show parallel lines. That is four parameters! Can also do the same thing with income and treatment. That will be a much worse model. Save interaction for five parameter chapter. -->
<!-- Add page 217 to selecting variables. Simple version. Can't talk about everything. Can't talk about interactions, for example. Talk about testing and how stupid it is! -->
<!-- Write out better models make better predictions on new data. Concepts! Cross validation. Leave one out. Blah, blah, blah. -->
<!-- Going back to att_end models. Then loo() and loo_compare(). -->
<p><em>This chapter is still a DRAFT. Check back in a few weeks.</em></p>
<p>In our haste to make progress — to get all the way through the process of building, interpreting and using models — we have given short shrift to some of the messy details of model building and evaluation. This chapter fills in those lacunae. We will also introduce models with four parameters.</p>
<div id="transforming-variables" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Transforming variables<a class="anchor" aria-label="anchor" href="#transforming-variables"><i class="fas fa-link"></i></a>
</h2>
<p>It is often convenient to transform a predictor variable.</p>
<div id="centering" class="section level3" number="9.1.1">
<h3>
<span class="header-section-number">9.1.1</span> Centering<a class="anchor" aria-label="anchor" href="#centering"><i class="fas fa-link"></i></a>
</h3>
<p>Recall our model of <code>income</code> as a function of <code>age</code>. Mathematics:</p>
<p><span class="math display">\[ y_i = \beta_0  + \beta_1 age_i + \epsilon_i\]</span></p>
<p>We fit this using the <code>trains</code> data from <strong>primer.data</strong>.</p>
<div class="sourceCode" id="cb741"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">primer.data</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb742"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">income</span> <span class="op">~</span> <span class="va">age</span>, 
         data <span class="op">=</span> <span class="va">trains</span>, 
         refresh <span class="op">=</span> <span class="fl">0</span>,
         seed <span class="op">=</span> <span class="fl">9</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_1</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median   MAD_SD  
## (Intercept) 103379.6  24657.3
## age            904.7    561.4
## 
## Auxiliary parameter(s):
##       Median  MAD_SD 
## sigma 74166.4  5146.6</code></pre>
<p>There is nothing wrong with this model. Yet the interpretation of <span class="math inline">\(\beta_0\)</span>, the intercept in the regression, is awkward. It means the average income for people of age zero. Yet that is useless! There are no people of zero age in our data. And, even if there were, it would be weird to think about such people taking the commuter trade into Boston and filling out our survey forms.</p>
<p>It is easy, however, to <em>transform</em> <code>age</code> into a variable which makes the intercept more meaningful. Consider a new variable, <code>c_age</code>, which is <code>age</code> minus the average age in the sample. Using this <strong>c</strong>entered version of age does not change the predictions or residuals in the model, but it does make the intercept easier to interpret.</p>
<div class="sourceCode" id="cb744"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains_2</span> <span class="op">&lt;-</span> <span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>c_age <span class="op">=</span> <span class="va">age</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span><span class="op">)</span>

<span class="va">fit_1_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">income</span> <span class="op">~</span> <span class="va">c_age</span>, 
                    data <span class="op">=</span> <span class="va">trains_2</span>, 
                    refresh <span class="op">=</span> <span class="fl">0</span>,
                    seed <span class="op">=</span> <span class="fl">9</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_1_c</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median   MAD_SD  
## (Intercept) 141804.2   7188.0
## c_age          906.7    572.9
## 
## Auxiliary parameter(s):
##       Median  MAD_SD 
## sigma 74273.6  4882.0</code></pre>
<p>The intercept, 141,804, is the expected income for someone with <code>age_c = 0</code>, i.e., someone of an average age in the data, which is around 42.</p>
</div>
<div id="scaling" class="section level3" number="9.1.2">
<h3>
<span class="header-section-number">9.1.2</span> Scaling<a class="anchor" aria-label="anchor" href="#scaling"><i class="fas fa-link"></i></a>
</h3>
<p>Centering — changing a variable via addition/subtraction — often makes the intercept easier to interpret. Scaling — changing a variable via multiplication/division — often makes it easier to interpret coefficients. The most common scaling method is to divide the variable by its standard deviation.</p>
<div class="sourceCode" id="cb746"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains_3</span> <span class="op">&lt;-</span> <span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>s_age <span class="op">=</span> <span class="va">age</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span><span class="op">)</span>

<span class="va">fit_1_s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">income</span> <span class="op">~</span> <span class="va">s_age</span>, 
                    data <span class="op">=</span> <span class="va">trains_3</span>, 
                    refresh <span class="op">=</span> <span class="fl">0</span>,
                    seed <span class="op">=</span> <span class="fl">9</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_1_s</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median   MAD_SD  
## (Intercept) 103061.4  25235.6
## s_age        11121.0   6921.6
## 
## Auxiliary parameter(s):
##       Median  MAD_SD 
## sigma 74124.8  4959.5</code></pre>
<p><code>s_age</code> is age <strong>s</strong>caled by its own standard deviation. A change in one unit of <code>s_age</code> is the same as a change in one standard deviation of the <code>age</code>, which is about 12. The interpretation of <span class="math inline">\(\beta_1\)</span> is now:</p>
<p><em>When comparing two people, one about 1 standard deviation worth of years older than the other, we expect the older person to earn about 11,000 more.</em></p>
<p>But, because we scaled without centering, the intercept is now back to the (nonsensical) meaning of the expected income for people of age 0.</p>
</div>
<div id="z-scores" class="section level3" number="9.1.3">
<h3>
<span class="header-section-number">9.1.3</span> <em>z</em>-scores<a class="anchor" aria-label="anchor" href="#z-scores"><i class="fas fa-link"></i></a>
</h3>
<p>The most common transformation applies both centering and scaling. The base R function <code><a href="https://rdrr.io/r/base/scale.html">scale()</a></code> subtracts the mean and divides by the standard deviation. A variable so transformed is a “<em>z</em>-score,” meaning a variable with a mean of zero and a standard deviation of one. Using <em>z</em>-scores makes interpretation easier, especially when we seek to compare the importance of different predictors.</p>
<div class="sourceCode" id="cb748"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains_4</span> <span class="op">&lt;-</span> <span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>z_age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span><span class="op">)</span>

<span class="va">fit_1_z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">income</span> <span class="op">~</span> <span class="va">z_age</span>, 
                    data <span class="op">=</span> <span class="va">trains_4</span>, 
                    refresh <span class="op">=</span> <span class="fl">0</span>,
                    seed <span class="op">=</span> <span class="fl">9</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_1_z</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median   MAD_SD  
## (Intercept) 141650.2   7101.3
## z_age        10899.1   6712.0
## 
## Auxiliary parameter(s):
##       Median  MAD_SD 
## sigma 74300.4  5019.0</code></pre>
<p>The two parameters are easy to interpret after this transformation.</p>
<p><em>The expected income of someone of average age, which is about 42 in this study, is about 142,000 dollars.</em></p>
<p><em>When comparing two individuals who differ in age by one standard deviation, which is about 12 years in this study, the older person is expected to earn about 11,000 more than the younger.</em></p>
<p>Note that, when using <em>z</em>-scores, we would often phrase this comparison in terms of “sigmas.” One person is “one sigma” older than another person means that they are one standard deviation older. This is simple enough, once you get used to it, but also confusing since we are already using the word “sigma” to mean <span class="math inline">\(\sigma\)</span>, the standard deviation of <span class="math inline">\(\epsilon_i\)</span>. Alas, <em>language is something we deal with rather than control.</em> You will hear the same word “sigma” applied to both concepts, even in the same sentence. Determine meaning by context.</p>
</div>
<div id="taking-logs" class="section level3" number="9.1.4">
<h3>
<span class="header-section-number">9.1.4</span> Taking logs<a class="anchor" aria-label="anchor" href="#taking-logs"><i class="fas fa-link"></i></a>
</h3>
<p>It is often helpful to take the log of predictor variables, especially in cases in which their distribution is skewed. You should generally only take the log of variables for which all the values are strictly positive. The log of a negative number is not defined. Consider the number of registered voters (<code>rv13</code>) at each of the polling stations in <code>kenya</code>.</p>
<div class="sourceCode" id="cb750"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">kenya</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">rv13</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span>

<span class="va">rv_p</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">rv13</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu">geom_histogram</span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Registered Voters"</span>,
         y <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> 

<span class="va">log_rv_p</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">rv13</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu">geom_histogram</span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Log of Registered Voters"</span>,
         y <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">expand_limits</span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">175</span><span class="op">)</span><span class="op">)</span>

<span class="va">rv_p</span> <span class="op">+</span> <span class="va">log_rv_p</span> <span class="op">+</span>
  <span class="fu">plot_annotation</span><span class="op">(</span>title <span class="op">=</span> <span class="st">'Registered Votes In Kenya Communities'</span>,
                  subtitle <span class="op">=</span> <span class="st">"Taking logs helps us deal with outliers"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-598-1.png" width="100%"></div>
<p>Most experienced data scientists would use the log of <code>rv13</code> rather than the raw value. Comments:</p>
<ul>
<li><p>We do not know the “true” model. Who is to say that a model using the raw value is right or wrong?</p></li>
<li><p>Check whether or not this choice meaningfully effects the answer to your question. Much of the time, it won’t. That is, our inferences are often fairly “robust” to small changes in the model. If you get the same answer with <code>rv13</code> as from <code>log_rv13</code>, then no one cares which you use.</p></li>
<li><p>Follow the conventions in your field. If everyone does X, then you should probably do X, unless you have a good reason not to. If you do have such a reason, explain it prominently.</p></li>
<li><p>Most professionals, when presented with data distributed like <code>rv13</code> would take the log. Professionals hate (irrationally?) outliers. Any transformation which makes a distribution look more normal is generally considered a good idea.</p></li>
</ul>
<p>Many of these suggestions apply to every aspect of the modeling process.</p>
<!-- Split out general advice to elsewhere. -->
</div>
<div id="adding-transformed-terms" class="section level3" number="9.1.5">
<h3>
<span class="header-section-number">9.1.5</span> Adding transformed terms<a class="anchor" aria-label="anchor" href="#adding-transformed-terms"><i class="fas fa-link"></i></a>
</h3>
<p>Instead of simply transforming variables, we can add more terms which are transformed versions of a variable. Consider the relation of <code>height</code> to <code>age</code> in <code>nhanes</code>. Let’s start by dropping the missing values.</p>
<div class="sourceCode" id="cb751"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">no_na_nhanes</span> <span class="op">&lt;-</span> <span class="va">nhanes</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">height</span>, <span class="va">age</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span> </code></pre></div>
<p>Fit and plot a simple linear model:</p>
<div class="sourceCode" id="cb752"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nhanes_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">age</span>,
                     data <span class="op">=</span> <span class="va">no_na_nhanes</span>,
                     refresh <span class="op">=</span> <span class="fl">0</span>,
                     seed <span class="op">=</span> <span class="fl">47</span><span class="op">)</span>

<span class="va">no_na_nhanes</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">nhanes_1</span><span class="op">)</span><span class="op">)</span>, 
              color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Age and Height"</span>,
         subtitle <span class="op">=</span> <span class="st">"Children are shorter, but a linear fit is poor"</span>,
         x <span class="op">=</span> <span class="st">"Age"</span>,
         y <span class="op">=</span> <span class="st">"Height (cm)"</span>,
         caption <span class="op">=</span> <span class="st">"Data source: NHANES"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-600-1.png" width="100%"></div>
<p>That is not a very good model, obviously.</p>
<p>Adding a quadratic term makes it better. (Note the need for <code><a href="https://rdrr.io/r/base/AsIs.html">I()</a></code> in creating the squared term within the <code>formula</code> argument.)</p>
<div class="sourceCode" id="cb753"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nhanes_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">age</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,
                     data <span class="op">=</span> <span class="va">no_na_nhanes</span>,
                     refresh <span class="op">=</span> <span class="fl">0</span>,
                     seed <span class="op">=</span> <span class="fl">33</span><span class="op">)</span>

<span class="va">no_na_nhanes</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">nhanes_2</span><span class="op">)</span><span class="op">)</span>, 
              color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Age and Height"</span>,
         subtitle <span class="op">=</span> <span class="st">"Quadratic fit is much better, but still poor"</span>,
         x <span class="op">=</span> <span class="st">"Age"</span>,
         y <span class="op">=</span> <span class="st">"Height (cm)"</span>,
         caption <span class="op">=</span> <span class="st">"Data source: NHANES"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-601-1.png" width="100%"></div>
<p>Still, we have not made use of our background knowledge in creating these variables. We know that people don’t get any taller after age 18 or so. Let’s create variables which capture that break.</p>
<div class="sourceCode" id="cb754"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nhanes_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">age</span> <span class="op">&gt;</span> <span class="fl">18</span>, <span class="fl">18</span>, <span class="va">age</span><span class="op">)</span><span class="op">)</span>,
                     data <span class="op">=</span> <span class="va">no_na_nhanes</span>,
                     refresh <span class="op">=</span> <span class="fl">0</span>,
                     seed <span class="op">=</span> <span class="fl">23</span><span class="op">)</span>

<span class="va">no_na_nhanes</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">age</span>, y <span class="op">=</span> <span class="va">height</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">nhanes_3</span><span class="op">)</span><span class="op">)</span>, 
              color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Age and Height"</span>,
         subtitle <span class="op">=</span> <span class="st">"Domain knowledge makes for better models"</span>,
         x <span class="op">=</span> <span class="st">"Age"</span>,
         y <span class="op">=</span> <span class="st">"Height (cm)"</span>,
         caption <span class="op">=</span> <span class="st">"Data source: NHANES"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-602-1.png" width="100%"></div>
<p>The point is that we should not take the variables we receive as <em>given</em>. We are the captains of our souls. We transform variables as needed.</p>
<!-- ### If parameters are unicorns, why bother with transformations? -->
<!-- * standardizing variables. Key advantage is to make the coefficients easier to interpret. Even though the "right" thing to do in looking at models is to use posterior_* to look at model predictions, this takes some time. It is very handy, first pass, to look at all the coefficients and get a sense of which ones are "interesting." Then, focus on those when making newobs tibbles. -->
</div>
<div id="transforming-the-outcome-variable" class="section level3" number="9.1.6">
<h3>
<span class="header-section-number">9.1.6</span> Transforming the outcome variable<a class="anchor" aria-label="anchor" href="#transforming-the-outcome-variable"><i class="fas fa-link"></i></a>
</h3>
<p>Transforming predictor variables is uncontroversial. It does not matter much. Change most continuous predictor variables to <span class="math inline">\(z\)</span>-scores and you won’t go far wrong. Or keep them in their original form, and take care with your interpretations. It’s all good.</p>
<p>Transforming the outcome variable is a much more difficult question. Imagine that we seek to create a model which explains <code>rv13</code> from the <code>kenya</code> tibble. Should we transform it?</p>
<ul>
<li><p>Maybe? There are no right answers. A model with <code>rv13</code> as the outcome variable is different from a model with <code><a href="https://rdrr.io/r/base/Log.html">log(rv13)</a></code> as the outcome. The two are not directly comparable.</p></li>
<li><p>Much of the same advice with regard to taking logs of predictor variables applies here as well.</p></li>
</ul>
<p>See <span class="citation"><a href="references.html#ref-roas" role="doc-biblioref">Gelman, Hill, and Vehtari</a> (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span></p>
</div>
</div>
<div id="selecting-variables" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Selecting variables<a class="anchor" aria-label="anchor" href="#selecting-variables"><i class="fas fa-link"></i></a>
</h2>
<p>How do we decide which variables to include in a model? There is no one right answer to this question. Our advice is to keep a variable X if any of the following circumstances apply:</p>
<ul>
<li><p>The variable has a large and well-estimated coefficient. This means, roughly, that the 95% confidence interval excludes zero.</p></li>
<li><p>Underlying theory/observation suggests that X has a meaningfully connection to the outcome variable.</p></li>
<li><p>It is standard in your field to include X in such regressions.</p></li>
<li><p>Your boss/client/reviewer/supervisor wants to include X.</p></li>
</ul>
<!-- * Creating new variables, especially by combining different ones into one combined variable. -->
</div>
<div id="comparing-models-in-theory" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Comparing models in theory<a class="anchor" aria-label="anchor" href="#comparing-models-in-theory"><i class="fas fa-link"></i></a>
</h2>
<p>Deciding which variables to include in a model is a subset of the larger question: How do we decide which model, out of the set of possible models, to choose?</p>
<p>Consider two models which explain attitudes to immigration among Boston commuters.</p>
<div class="sourceCode" id="cb755"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_liberal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">att_end</span> <span class="op">~</span> <span class="va">liberal</span>,
                  data <span class="op">=</span> <span class="va">trains</span>,
                  refresh <span class="op">=</span> <span class="fl">0</span>,
                  seed <span class="op">=</span> <span class="fl">42</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_liberal</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median MAD_SD
## (Intercept) 10.0    0.3  
## liberalTRUE -2.0    0.5  
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 2.7    0.2</code></pre>
<div class="sourceCode" id="cb757"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_att_start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">att_end</span> <span class="op">~</span> <span class="va">att_start</span>,
                  data <span class="op">=</span> <span class="va">trains</span>,
                  refresh <span class="op">=</span> <span class="fl">0</span>,
                  seed <span class="op">=</span> <span class="fl">85</span><span class="op">)</span>

<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">fit_att_start</span>, detail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<pre><code>##             Median MAD_SD
## (Intercept) 1.6    0.4   
## att_start   0.8    0.0   
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 1.4    0.1</code></pre>
<p>They both seem like good models! The results make sense. People who are liberal have more liberal attitudes about immigration, so we would expect their <code>att_end</code> scores to be lower. We would also expect people to provide similar answers in two surveys administered a week or two apart. It makes sense that those with higher (more conservative) values for <code>att_start</code> would also have higher values for <code>att_end</code>.</p>
<p>How do we choose between these models?</p>
<div id="better-models-make-better-predictions" class="section level3" number="9.3.1">
<h3>
<span class="header-section-number">9.3.1</span> Better models make better predictions<a class="anchor" aria-label="anchor" href="#better-models-make-better-predictions"><i class="fas fa-link"></i></a>
</h3>
<p>The most obvious criteria for comparing models is the accuracy of the predictions. For example, consider the use of <code>liberal</code> to predict <code>att_end</code>.</p>
<div class="sourceCode" id="cb759"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>pred_liberal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_liberal</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pred_liberal</span>, y <span class="op">=</span> <span class="va">att_end</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_jitter</span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.05</span>, height <span class="op">=</span> <span class="fl">0.2</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Modeling Attitude Toward Immigration"</span>,
         subtitle <span class="op">=</span> <span class="st">"Liberals are less conservative"</span>,
         x <span class="op">=</span> <span class="st">"Predicted Attitude"</span>,
         y <span class="op">=</span> <span class="st">"True Attitude"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-605-1.png" width="100%"></div>
<!-- DK: Could put this discussion in fig.cap. Could add some details to the plots to indicate the points that I am talking about. Should create an animation, which brings in new point, forecasts it, and then measures how wrong the model was. -->
<p>Because there are only two possible values for <code>liberal</code> — TRUE and FALSE — there are only two predictions which this model will make: about 10 for <code>liberal == FALSE</code> and about 8 for <code>liberal == TRUE</code>. (The points in the above plot are jittered.) For some individuals, these are perfect predictions. For others, they are poor predictions. (Note the two individuals who are <code>liberal == TRUE</code>, and who the model thinks will have <code>att_end == 8</code>, but who have <code>att_end == 15</code>. The model got them both very, very wrong.)</p>
<p>Consider our second model, using <code>att_start</code> to forecast <code>att_end</code>.</p>
<div class="sourceCode" id="cb760"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>pred_liberal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_att_start</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">pred_liberal</span>, y <span class="op">=</span> <span class="va">att_end</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_jitter</span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.05</span>, height <span class="op">=</span> <span class="fl">0.2</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Modeling Attitude Toward Immigration"</span>,
         subtitle <span class="op">=</span> <span class="st">"Survey responses are somewhat consistent"</span>,
         x <span class="op">=</span> <span class="st">"Predicted Attitude"</span>,
         y <span class="op">=</span> <span class="st">"True Attitude"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-606-1.png" width="100%"></div>
<p>Because <code>att_end</code> takes on 13 unique values, the model makes 13 unique predictions. Some of those predictions are perfect! But others are very wrong. Note the individual with a predicted <code>att_end</code> of around 9 but with an actual value of <code>15</code>. That is a big miss!</p>
<p>Rather than looking at individual cases, we need to look at the errors for all the predictions. Fortunately, a prediction error is the same thing as a residual, which is easy enough to calculate.</p>
<div class="sourceCode" id="cb761"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">att_end</span>, <span class="va">att_start</span>, <span class="va">liberal</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>pred_lib <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_liberal</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>resid_lib <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_liberal</span><span class="op">)</span> <span class="op">-</span> <span class="va">att_end</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>pred_as <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_att_start</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>resid_as <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_att_start</span><span class="op">)</span> <span class="op">-</span> <span class="va">att_end</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 115 x 7
##    att_end att_start liberal pred_lib resid_lib pred_as resid_as
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;
##  1      11        11 FALSE      10.0    -0.974    10.6    -0.399
##  2      10         9 FALSE      10.0     0.0259    8.97   -1.03 
##  3       5         3 TRUE        8.02    3.02      4.08   -0.916
##  4      11        11 FALSE      10.0    -0.974    10.6    -0.399
##  5       5         8 TRUE        8.02    3.02      8.16    3.16 
##  6      13        13 FALSE      10.0    -2.97     12.2    -0.769
##  7      13        13 FALSE      10.0    -2.97     12.2    -0.769
##  8      11        10 FALSE      10.0    -0.974     9.79   -1.21 
##  9      12        12 FALSE      10.0    -1.97     11.4    -0.584
## 10      10         9 FALSE      10.0     0.0259    8.97   -1.03 
## # … with 105 more rows</code></pre>
<p>Let’s look at the square root of the average squared error.</p>
<div class="sourceCode" id="cb763"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">trains</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">att_end</span>, <span class="va">att_start</span>, <span class="va">liberal</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>lib_err <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_liberal</span><span class="op">)</span> <span class="op">-</span> <span class="va">att_end</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>as_err <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit_att_start</span><span class="op">)</span> <span class="op">-</span> <span class="va">att_end</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">summarize</span><span class="op">(</span>lib_sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">lib_err</span><span class="op">)</span><span class="op">)</span>,
            as_sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">as_err</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   lib_sigma as_sigma
##       &lt;dbl&gt;    &lt;dbl&gt;
## 1      2.68     1.35</code></pre>
<p>There are many different measures of the error which we might calculate. The squared difference is most common for historical reasons: it was the mathemtically most tractable in the pre-computer age. Having calculated a squared difference for each observation, we can sum them or take their average or take the square root of their average. All produce the same relative ranking, but the last is most popular because it (more or less) corresponds to the estimated <span class="math inline">\(\sigma\)</span> for a linear model. Note how these measures are the same as the ones produced by the Bayesian models created above.</p>
<!-- DK: Could make a movie where we get an X value, we calculate a prediction, we plot it, then we plot the truth, then we measure the distance, then we calculate a squared error. Then speed up the movie, doing it for all the points.  -->
<!-- DK: Could discuss uncertainty in the estimated sigma. But left it out in this draft. -->
<p>Sadly, it is not wise to simply select the model which fits the data best because doing so can be misleading. After all, you are cheating! You are using that very data to select your parameters and then, after using the data once, turning around and “checking” to see how well your model fits the data. It better fit! You used it to pick your parameters! This is the danger of <em>overfitting</em>.</p>
</div>
<div id="beware-overfitting" class="section level3" number="9.3.2">
<h3>
<span class="header-section-number">9.3.2</span> Beware overfitting<a class="anchor" aria-label="anchor" href="#beware-overfitting"><i class="fas fa-link"></i></a>
</h3>
<p>One of the biggest dangers in data science is <em>overfitting</em>, using a model with too many parameters which fits the data we have too well and, therefore, works poorly on data we have yet to see. Consider a simple example with 10 data points.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-609-1.png" width="100%"></div>
<p>What happens when we fit a model with one predictor?</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-610-1.png" width="100%"></div>
<p>That is a reasonable model. It does not fit the data particularly well, but we certainly believe that higher values of <code>x</code> are associated with higher values of <code>y</code>. A linear fit is not unreasonable.</p>
<p>But we can also use some of the lessons from above and try a quadratic fit by adding <span class="math inline">\(x^2\)</span> as a predictor.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-611-1.png" width="100%"></div>
<p>Is this a better model? Maybe?</p>
<p>But why stop at adding <span class="math inline">\(x^2\)</span> to the regression? Why not add <span class="math inline">\(x^3\)</span>, <span class="math inline">\(x^4\)</span> and all the way to <span class="math inline">\(x^9\)</span>? When we do so, the fit is much better.</p>
<div class="sourceCode" id="cb765"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">nine_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">9</span><span class="op">)</span>,
                       data <span class="op">=</span> <span class="va">ovrftng</span><span class="op">)</span>

<span class="va">newdata</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,
                  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">nine_pred</span>, 
                              newdata <span class="op">=</span> <span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">ovrftng</span> <span class="op">%&gt;%</span> 
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">newdata</span>, 
              <span class="fu">aes</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">labs</span><span class="op">(</span>title <span class="op">=</span> <span class="st">"`y` as a 9-Degree Polynomial Function of `x`"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu">scale_y_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-612-1.png" width="100%"></div>
<p><em>If the only criteria we cared about was how well the model predicts using the data on which the parameters were estimated, then a model with more parameters will always be better.</em> But that is not what truly matters. What matters is how well the model works on data which was not used to create the model.</p>
</div>
<div id="better-models-make-better-predictions-on-new-data" class="section level3" number="9.3.3">
<h3>
<span class="header-section-number">9.3.3</span> Better models make better predictions on new data<a class="anchor" aria-label="anchor" href="#better-models-make-better-predictions-on-new-data"><i class="fas fa-link"></i></a>
</h3>
</div>
</div>
<div id="comparing-models-in-practice" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Comparing models in practice<a class="anchor" aria-label="anchor" href="#comparing-models-in-practice"><i class="fas fa-link"></i></a>
</h2>
<!-- Run loo (on both models from above). Explain each part. Don't use math they don't know. Focus on elpd_loo, since that is what compare_loo does. Then, run compare_loo, explain what it shows. Then, we choose the att_start model. It does much better! -->
<!-- ### Selecting the rows -->
<!-- ## Testing is nonsense -->
</div>
<div id="parallel-lines" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Parallel lines<a class="anchor" aria-label="anchor" href="#parallel-lines"><i class="fas fa-link"></i></a>
</h2>
<!-- att_end ~ liberal + att_start. Same thing as chapters before. Show graphic of parallel lines. Cardinal virtues as always. And, extra, at the end we can use loo_compare to see if this model is better than simpler model of att_end ~ att_start. -->
</div>
<div id="summary-9" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Summary<a class="anchor" aria-label="anchor" href="#summary-9"><i class="fas fa-link"></i></a>
</h2>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="three-parameters.html"><span class="header-section-number">8</span> Three Parameters</a></div>
<div class="next"><a href="five-parameters.html"><span class="header-section-number">10</span> Five Parameters</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#four-parameters"><span class="header-section-number">9</span> Four Parameters</a></li>
<li>
<a class="nav-link" href="#transforming-variables"><span class="header-section-number">9.1</span> Transforming variables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#centering"><span class="header-section-number">9.1.1</span> Centering</a></li>
<li><a class="nav-link" href="#scaling"><span class="header-section-number">9.1.2</span> Scaling</a></li>
<li><a class="nav-link" href="#z-scores"><span class="header-section-number">9.1.3</span> z-scores</a></li>
<li><a class="nav-link" href="#taking-logs"><span class="header-section-number">9.1.4</span> Taking logs</a></li>
<li><a class="nav-link" href="#adding-transformed-terms"><span class="header-section-number">9.1.5</span> Adding transformed terms</a></li>
<li><a class="nav-link" href="#transforming-the-outcome-variable"><span class="header-section-number">9.1.6</span> Transforming the outcome variable</a></li>
</ul>
</li>
<li><a class="nav-link" href="#selecting-variables"><span class="header-section-number">9.2</span> Selecting variables</a></li>
<li>
<a class="nav-link" href="#comparing-models-in-theory"><span class="header-section-number">9.3</span> Comparing models in theory</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#better-models-make-better-predictions"><span class="header-section-number">9.3.1</span> Better models make better predictions</a></li>
<li><a class="nav-link" href="#beware-overfitting"><span class="header-section-number">9.3.2</span> Beware overfitting</a></li>
<li><a class="nav-link" href="#better-models-make-better-predictions-on-new-data"><span class="header-section-number">9.3.3</span> Better models make better predictions on new data</a></li>
</ul>
</li>
<li><a class="nav-link" href="#comparing-models-in-practice"><span class="header-section-number">9.4</span> Comparing models in practice</a></li>
<li><a class="nav-link" href="#parallel-lines"><span class="header-section-number">9.5</span> Parallel lines</a></li>
<li><a class="nav-link" href="#summary-9"><span class="header-section-number">9.6</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PPBDS/primer/blob/master/09-four-parameters.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PPBDS/primer/edit/master/09-four-parameters.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Preceptor’s Primer for Bayesian Data Science</strong>" was written by David Kane. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
