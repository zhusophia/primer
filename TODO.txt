# Topics

* Need to add fig.cap to any R code chunk for a figure which we want to reference. "If we assign a figure caption to a code chunk via the chunk option fig.cap, R plots will be put into figure environments, which will be automatically labeled and numbered, and can also be cross-referenced."

* Fix these messages:

Output created: docs/index.html
Warning message:
`group_by_()` is deprecated as of dplyr 0.7.0.
Please use `group_by()` instead.
See vignette('programming') for more help
This warning is displayed once every 8 hours.
Call `lifecycle::last_warnings()` to see where this warning was generated. 

* Use ragg? ragg can be used when knitting Rmarkdown files by setting dev="ragg_png" in the code chunk options

https://www.tidyverse.org/blog/2021/02/modern-text-features/

* Prevent the rayshader images from popping up when Chapter 5 is knitted.

* Add something about searching Github to help.

* Think about the difference between the *posterior distribution* of average height and the *posterior probability distribution*. Right now, we only use the latter. But the draws which are produced from epred() and predict() are really more examples of the former. Aren't they? That is, 4,000 height values is a *distribution*, as are all vectors, and it is *posterior* since we created it with a function that starts with "posterior". But nor is it a probability distribution since we have not normalized it yet. Shouldn't we weave this connection throughout the book. 

* Should I use MAD_SD, MAD, mad or what? Should be consistent.

* Standardize use of "tidyverse". Only two choices: Either Tidyverse, when referring to the concept and/or to the collection of packages, or **tidyverse**, when referring to the package itself. Never use "tidyverse."

* Add ModernDive common problems isssues: https://moderndive.com/C-appendixC.html#data-wrangling

* Start using "When comparing" everywhere.

* Fix tools to include discussion of Git for Windows and setting up the Terminal correctly: https://happygitwithr.com/shell.html#windows-shell-hell. 

* Split maps into census and maps. Combine with ipums. Add code for making ipums graphics.

* Every model should feature a plot of predicted values and true outcomes. The decomposition is fine as far as it goes, but it is not the key image.

* Think harder about p() and Prob(). Which goes where?

* Use fitted() or predict() or both?

* Need testing in each chapter.

* Find/remove all usage of "controlling for x, we see". Use "adjust" instead.

* What do we think about the width of the code in the book? Sure seems like the comment lines go on for too long. Maybe? I don't like the way they care cut off in my Ipad, but . . . do many students read on Ipads?

* https://xkcd.com/2048/

* Show the secret weapon of doing the same regression many times and then gathering the results. nest_by(), perhaps.


* The elipses should be vertical, not horizontal in all Preceptor Tables.

* Discuss the meaning of sigma more often. Really only need one sentence, but should give that sentence almost every time.

* Include links to disputes about governors work:

https://erikgahner.dk/2020/a-response-to-andrew-gelman/
https://statmodeling.stat.columbia.edu/2020/07/02/no-i-dont-believe-that-claim-based-on-regression-discontinuity-analysis-that/
https://github.com/jonspring/discontinuity/blob/master/fileb23c55435f90.gif


* Make rayshader movies for all the 3D plots in Chapter 5. Guidance:
https://joeystanley.com/blog/3d-vowel-plots-with-rayshader

* Expand the Shiny appendix to highlight those aspects of Shiny that are most used by students for their final projects. Start with panel tabs. And math. And regression tables. Maybe switch the entire focus to the Mastering Shiny book? Are there cool things in Shiny 1.6 to discuss?

* Greek letters are for parameters which we can never observe. Latin letters are for observables.

* Explain transformations and centering, and maybe normalization as well. Sometimes we want to measure height in centimenters, sometimes in feet. Sometimes using z-scores is best. Sometimes percentiles. Discuss continuous versus categorial variables. Is there room to do this in chapter 7, or at least to introduce it. Or doe this wait till chapter 9?

* Chapter 7 should introduce, gently, the concept of in-sample and out-of-sample. As well as predictive accuracy as being a good way to judge how good your model is. What are some useful measures of predictive accuracy? Discuss our objective functions; minimize what? when would median be better than mean? Find a skewed data set and show how guessing the median works better than guessing the mean, if you care about absolute difference. (Can we estimate the median with stan_glm()?) Bias/Variance == Underfitting/Overfitting

* First, we can just print it. Chapter 7 walks the reader through all the parts of a stan_glm() model in detail. Later chapters will also show the printed model, but can move more quickly. Second, we create a summary table of the model using **gtsummary**. Note that this is just a different view of the same model. We don't show some things --- like sigma --- that we did show when just printing. We do show other things, like the 95% confidence interval which we did not show before. Neither is better! We use the one which is most helpful to our audience. Third, we use **tidybayes** to show histograms of the posterior distributions. The posterior is the underlying reality, the closest to the "truth" which we are going to get. The printed and table outputs are just summaries of the posterior. We might not show all three things every time, but we certainly always show the posterior. Graphics are pretty!

* After noting this formula, each example should create a plot with three histograms in a row --- left-to-right, the outcome (i.e., a histogram or density of Y), the fitted values (which is sometimes a spike, sometimes two spikes and so on) and, finally, the residuals. This highlights how we have *decomposed* the outcome into two parts: the model and the unmodeled variation. This belongs in the Courage chapter because it is a way of understanding the model we have made.

* We need a "machine" which generates these predictions, which is the same thing as a machine which fills in all the question marks in the Actual Preceptor Table, which is the same thing as a machine which produces "fake data" which looks a lot like our actual data.  


* This also leads directly to the concept of *posterior predictive checks*, which is just fancy terminology for helping to see if your model makes sense. If your model is reasonable, then you would expect to see Z (a feature of the real data) in either new data or in fake data generated by your model. If you see Z, then you should have more faith in your model. If you don't, then something is wrong. 

## To Discuss Later

* Fix this for next fall: https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/

* Discuss: Should "posterior probability distribution" become "ppd" or "PPD" everywhere?


* Track down these warnings from the end of book-building. Not sure where they come from.

Output created: docs/index.html
Warning messages:
1: Removed 19 rows containing missing values (geom_point). 
2: The label(s) fig:histogram not found 

DK: I think this is chapter 1 and the use of xlim!


* Lots of interesting items: . I like the hack of making your Rmd an index.Rmd and then the html will appear as a Github pages for free.


* Should use summary(fit_1) and discuss at some point. But when? Maybe Chapter 10?

* Do we need a cool graphics appendix, with  brief descriptions, pretty pictures from cool packages like: ggrepel, gghighlights, plotly. Others?

* posterior package useful?

* More discussion of what it means to "control for" something in a regression. Right now, we don't mention this until chapter 11. Needs to be covered earlier, especially in chapter 9. That sets the stage for later.

* Use tidybayes? Or just ggdist?


* Standardize notation. What are predicted/fitted values? Use y_i everywhere, instead of using problem specific terms? That seems a bad (good?!) idea.

* Generate some error messages and then show that they can teach you something. Object does not exist. filter only have one equal sign, and so on. Do this all the time. Normalize the generation and processing of error messages.

* Discuss base R versus tidyverse so that students are not confused when they see base R. Maybe this is week 3 in functions? And have a tutorial for this.

* Teach more file management, organization, use of R scripts. (Should have done that in some of the problem sets. Maybe a milestone could require that the graphic is created with a .R script with an image saved and then placed in the app directory.) Maybe add to tools? Create a tutorial for week 4?


*  Better workflow, automatic (with click confirmation) replacement of docs/ after successful check. Two parts: First, change the check so that it builds the book nicely. (Maybe not necessary. Maybe building the book in junk/ is OK?) Second, move the newly created book --- once it is accepted --- to docs/ on the master branch. Should we be taking multiple branches more seriously. Probably.
  + Things to discuss:
    - This change will prevent authors from easily knitting individual chapters. I will explore alternatives.
    - Two ways of handing auto-building and auot-updating:
      - 1) Create a new development branch. Students will submit PR to that branch. When you are ready, you can send a PR to merge to the master
           branch. The changes will only be live when you merge the development branch to the master branch.
      - 2) Keep things as they are. Once a student submits a PR, the build will directly go into docs/ and if successful, you can accept the PR
           and the new changes to the book will immediately be live. If the build check fails, do not accept the PR or else the deployment might
           break.



## Older Material

Everything below needs to be reviewed and organized.

Interesting resources:



Discuss how to set a stable version of primary.data which we do not touch all semester, and then have a devel branch in which we are fixing all the mistakes.




Clean up bok repo to test this:

rm -rf .git
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/davidkane9/PPBDS.data.git
git push -u --force origin master

Add necessary references to the references.bib and ensure that they are called correctly.

## Social Media Plan

1) Students look at three main things when deciding to take a course (sent from one of our new followers on Instagram!):
  - Q Guide scores and reviews
  - The professor (or preceptor!)
  - Anecdotal stoties from friends

2) We need more from you! Pictures and vertical videos for Instagram about your everyday life. Students value the human connection even more in remote learning.

3) We also need more from Gov 50 alumn! I have an interactive story that will go up once we hit 250 followers that alumn will share. We can also create sponsored posts/stories if students are interested. I have already approved my personal account and will post a sponsored post soon.

4) Advertising logistics:
  - We can target 18-22 year-old users associated with Harvard College and living in the US.
  - $25 total, $5/day campaign will have an estimated reach of 2,500-6,600 accounts.
  - Depending on your budget, I suggest we run 2-4 of these campaigns in August.
  - Each campaign will promote one of our best performing posts: I have some appropriate memes scheduled to post soon and Q Guide Score Quotes.

## Book Building

* [*Bookdown*](https://bookdown.org/yihui/bookdown/) is the key reference. Build the book by following the instructions in _bookdown.yml. Those instructions end with a deployment to Github Pages via the doc/ directory.


## Things That Annoy Us

These are open projects with annoying details that we will revisit.

* ms-errors and simpsons-paradox. What do we do?

## Open Questions

* Need to start using tidybayes and ggdist. https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-rstanarm.html


* Is there a way to print out messages during the book building process so that you know where the process is? Maybe just a cat message at the end of Summary? Recall that we can't (?) use R code chunk names because duplicate code chunk names cause (still?) the process to blow up.


* Can you rebuild just a single chapter and then commit/push it? Right now, I have to rebuild the whole thing each time I want to make a single change. Takes too long.



## Other Items


* Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY




Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

https://committedtotape.shinyapps.io/freeR/


Replace all photos of activities with photos from Harvard, using Tsai.


# Appendices

Appendices have information that either a) a prof might reasonably decide not to assign or b) often contain material that students already know.

* Why Bayes?

* Messed up research articles. We need to prepare case studies of messed up articles. Start with those that Gelman cites. The tricky part is trying to figure out how to include these in class. And during which week do we use them.


* All the math you don't need to know. Bayes Theorem. Formulas. Normal distribution. Central limit theorem

* Advanced graphics, especially a tour of cool packages, including ggplotly and leaflet. gghighlight. ggstream.

* List of cool packages, googlesheet4 examples. : https://datavizm20.classes.andrewheiss.com/example/10-example/

* How to make an Rpubs and gists and saveWidgets:
https://datavizm20.classes.andrewheiss.com/example/10-example/

* Tufte and other graphics luminaries

* Leamer and other famous articles

* rtweet (Cassidy)

* Making memes. Someone should figure out which meme maker is best for R. Or maybe we make our own. And then we make lots of memes for the book!

* Map appendix should include some Matt Blackwell examples.




# From the Bookdown book

preview_chapter() and serve_book() as an aid to chapter writers.

webshot() tool for including images taken from webpages. Everytime we mention how cool source X is, we should provide a webshot of it. (And we should test that it exists.) Make the productivity chapter include way less of our prose.


p. 64 notes that adding the suffix 2 to various output formats gives you all the cool stuff, like figure captioning and numbering.

p. 74 has a useful discussion of configuration options for the _bookdown.yml file.

* rmd_subdir are subdirectories to search for source Rmd files. That seems critical for my submodule structure.

* output_dir is the output directory of the process (_book by default).

* clean is vector of files and directories to be cleaned by the clean_book() function.

pp. 5-6 discuss rmd_files as the way to define your own ordering for output files. This also goes in the _bookdown.yml file.












## Next Summer


* Consider this for entire document:  
html_document:
    code_folding: "hide"


Add Tukey quote about burning desire. 

* To Blog:

Entry about best class.
Why Bayesian

* Books

https://rstudio4edu.github.io/rstudio4edu-book/   
https://ubc-dsci.github.io/introduction-to-datascience/
https://monika76five.github.io/ProbBayes/
https://bookdown.org/roback/bookdown-BeyondMLR/
https://dtkaplan.github.io/DataComputingEbook/

* Courses

https://dataviz-2021.netlify.app/
https://jmbuhr.de/dataIntro20/
https://athanasiamo.github.io/tidyquintro/

* Other

https://evamaerey.github.io/flipbooks/about (use flipbooks for classroom exercises?)
https://nickch-k.github.io/EconometricsSlides/
https://holtzy.github.io/Pimp-my-rmd/

 https://fromthebottomoftheheap.net/2020/04/30/rendering-your-readme-with-github-actions/
 https://github.com/itsyaoyu/github_actions/blob/master/.github/workflows/main.yml
 https://www.willandskill.se/en/deleting-your-git-commit-history-without-removing-repo-on-github-bitbucket/

https://mdbeckman.github.io/JSM2020-Virtual/

* More cartoons like [xkcd](https://cran.r-project.org/package=RXKCD)

styler package

https://storywrangling.org/

https://desiree.rbind.io/post/2019/making-tip-boxes-with-bookdown-and-rmarkdown/ for making pretty boxes in the book

https://github.com/wikimedia/waxer for Wikipedia data

http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/

https://github.com/agmath/AppliedStatsInteractive

https://github.com/moodymudskipper/flow

https://github.com/ucbds-infra/ottr-sample

https://github.com/allisonhorst/stats-illustrations

https://bookdown.org/yihui/rmarkdown-cookbook/equatiomatic.html

Consider Netifly: https://cerebralmastication.com/2019/05/11/publishing-bookdown-to-netlify-automagically/

https://kieranhealy.org/categories/visualization/

https://openintro-ims.netlify.app/ 

https://education.rstudio.com/blog/2020/07/gtsummary/
https://moderndive.github.io/moderndive_labs/index.html
https://education.rstudio.com/blog/2020/07/learning-learnr/
https://rmarkdown.rstudio.com/authoring_shiny_prerendered.HTML




# FAS On Demand Meeting

## Package Issues

## Performance

Seems really slow, even with just 2 + 2

Notice how much longer it takes the tutorials to build on OnDemand relative to a local machine. Maybe?

Tools tuorial builds fine. Wrangling-A and B fail to build, but work locally. Biggest difference in Wrangling-A is that it works/copies local files. But Wrangling-B fails as well, and it is very average. Maybe all non-small tutorials fail? Timing out somehow? After testing, still an intermittent problem.


## Miscelaneous

* New graphics? https://www.openscapes.org/blog/2020/10/12/tidy-data/
  
----  

Why I am still getting this message when I commit? (I have configured these properly already. And restarted a new instance.)

 Committer: David Kane <u_241292_g_86443@holy2a02103.rc.fas.harvard.edu>
Your name and email address were configured automatically based
on your username and hostname. Please check that they are accurate.
You can suppress this message by setting them explicitly:

    git config --global user.name "Your Name"
    git config --global user.email you@example.com
----  

I am also being forced to provide my login/password even though I set up a Github PAT.
