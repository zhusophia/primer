# Priorities


Bryan Li. This is a pull request test.

Shyam Sai Bethina. Pull request test


## Students

Heather and Kevin -- chapter 1
Ajay (data types), Atilla (plots) and Bryan (more plots)-- chapter 2
Anmay -- chapter 3
Sophia and Arghayan -- chapter 4
Yuhan -- chapter 5
Ryan -- chapter 6
George -- chapter 7
Mahima -- chapter 8
Mak -- Chapter 10
Nuo Wen -- technical issues

# Topics

* https://clauswilke.com/dataviz/

* Output created: docs/index.html
Warning message:
In readLines(file) :
  incomplete final line found on '/var/folders/mk/lh99bg295msg8myvcf5yczkc0000gn/T//RtmpgXdsMq/file171757d88bd09'

* Work on Chapter 11. Revisit Cardinal Virtue discussion in chapter 5. Does it belong there? Or in Chapter 6? Or nowhere?

* Get rid of 90% of the parameter interpretations discussions. Parameters, much less the posterior distributions of parameters, are not that interesting. We don't care with complex models, so we should not care (much) with simple models. Got a substantive question? Ask it directly as a newobs.

* Consider this for entire document:
html_document:
    code_folding: "hide"

* Keep in mind that the rvars package is coming along and will serve as the new foundation for the posterior package. This will change how we plot posteriors in the future, probably with a new version of tidybayes. Working with ggdist directly is not the best approach, I think.

* Discuss: Should "posterior probability distribution" become "ppd" or "PPD" everywhere?

* Use the new tigris::shift_geometry() in map chapter to make Alaska, Hawaii easier to include in US maps. Example: https://gist.github.com/walkerke/6025153da606ee8711a77f689196299e.

* Use chrome_print() to make PDF files instead of having to worry about tinytex and other arcana: https://rdrr.io/cran/pagedown/man/chrome_print.html

* When do we start using the new pipe? Whenever that is, we will want to update Getting Started to make the new pipe the default for CMD-shift-M. Presumably, there is a command for doing so. Discussion: https://blog.rstudio.com/2021/06/09/rstudio-v1-4-update-whats-new/

* Add one or two other types of models. Maybe stan_gamm4(), for generalized additive models, or stan_polr(), for ordinal models. Or both? Idea is that the basic purpose of Justice is to choose a functional form. Given that, we ought to have a bunch of functional forms which we try. Sure wish that there were a stan_multilogit(), which would be an easy extention from logistic. (Maybe there is? I need to explore the different family arguments in stan_glm().) Something for time series might also be useful, given how common time series are in reality. Or maybe we can stick with stan_glm() and just use one of the other 6 or 7 family options. Maybe Gamma, which ensures that the outcome is positive. (Example: https://mc-stan.org/rstanarm/articles/continuous.html). Or poissson? Some of this might work well in chapter 8, since some of the left-hand side variables have few possible value and/or are always positive. multinomial/categorical regressions are available in the brms package. One way to still use rstanarm for this is discussed here: https://github.com/stan-dev/rstanarm/issues/20, trick is using Poisson count models.


Wisdom: Begin with the ideal Preceptor Table. Depends on the question. Might be all voters in Massachusetts. Might be just the Republican voters. This determines if we are causal or predictive.  Key is that sometimes you want to know multiple potential outcomes for person X. If so, you are doing a causal model. If, however, you only need to know one outcome --- often because just one outcome is conceivable --- then it is predictive. The ideal Preceptor table will generally not have any rows for data we actually have. We never really care about the causal effect in election X specifically. We want to make claims about elections in general.

Then look for data and explore that data. What must I assume about the population, to allow me to go forward? If the data is not "close enough" to my ideal Preceptor Table, I give up. Wisdom is about knowing when to quit. Going forward means assuming that the actual data and the data from the ideal Preceptor Table come from the same population.


With population, we make a distinction between Wisdom --- Are the rows from the same population? --- and Justice --- Are the rows we have data for *representative* of that population? That works nicely! Can we do the same thing wit columns? In our ideal Preceptor Table, we have a column called "treatment" which specifies the postcards we might send. With Wisdom, we need to decide if that treatment is drawn from the same population (?) of conceivable treatments as the "treatment" which was used in our data. Are the different things labelled "treatment" close enough that we can stack them in the same tibble? If no, then we give up. We can't go further.



Justice: Actual Preceptor Table, which is different from the ideal Preceptor Table in two ways. First, it includes the data we have. That is, it has more rows. Second, it has a bunch of missing values. (We could make an artificial distinction and say that the ideal Preceptor table never includes rows for data we have, but that is probably a bidge too far. Then again, with a time column, it is almost always true.) Then, representativeness (rows), validity (columns). In the ideal case, the data we have is perfectly representative of the population we want to estimate. That is, it is a random sample. In the ideal case, the columns mean the same thing in all rows. They are perfectly valid, but that is often not true.

If we lack perfect representativeness and/or perfect validity, then we can try to fix our mathematical structure. Or, we can just keep those failures in the back of our mind and then approach the posteriors we create

Assignment mechanism? Sampling mechanism?


Only the main functional form, with no variable names. Discussion of the error term.

Courage: For each model, write down the math, estimate the model, say something sensible about the regression table. Testing is stupid.

Temperance. Answer the question. Create a newobs, plug it into the model, calculate the outcome. Don't forget to add the error term if you are predicting. Then plot it. Be aware of the limits to the accuracy of your answer. Preceptor's Posterior.  All the cool themes. Bring it all together. Make the students say "Ahhh!" -->



* Preceptor's Posterior is a posterior for which all the assumptions are true. Just because the big Data Science Machine has spat out a posterior does not mean that you should believe it blindly.

* Replace geom_histogram with ggdist throughout, although leave the first example and show how ggdist just makes everything easier.

* Look to this for motivation: https://mc-stan.org/rstanarm/articles/continuous.html

* Need to add fig.cap to any R code chunk for a figure which we want to reference. "If we assign a figure caption to a code chunk via the chunk option fig.cap, R plots will be put into figure environments, which will be automatically labeled and numbered, and can also be cross-referenced."

* Use ragg? ragg can be used when knitting Rmarkdown files by setting dev="ragg_png" in the code chunk options

https://www.tidyverse.org/blog/2021/02/modern-text-features/

* Add the notion of Preceptor's Posterior earlier.

* Add something about searching Github to help.

* Stop spending time interpreting coefficients. Make fun of the practice. Instead, just ask a question and then answer it.

* $ git reset --soft HEAD~1

* The elipses should be vertical, not horizontal in all Preceptor Tables. fmt_markdown() would allow us to have vertical elipses in the Preceptor Tables.

* Discuss ps_2 to PS_2 problem on Github.

* Discuss relative paths and home directories more in Tools.

* Discuss col_types in read_cvs().

* Add grouping for line plots.

* Explaing age*gender versus age:gender distinction?

* Get rid of joins except left joins, and mention the others.

* Think about the difference between the *posterior distribution* of average height and the *posterior probability distribution*. Right now, we only use the latter. But the draws which are produced from epred() and predict() are really more examples of the former. Aren't they? That is, 4,000 height values is a *distribution*, as are all vectors, and it is *posterior* since we created it with a function that starts with "posterior". But nor is it a probability distribution since we have not normalized it yet. Shouldn't we weave this connection throughout the book.

* Should I use MAD_SD, MAD, mad or what? Should be consistent.

* Standardize use of "tidyverse". Only two choices: Either Tidyverse, when referring to the concept and/or to the collection of packages, or **tidyverse**, when referring to the package itself. Never use "tidyverse."

* Add ModernDive common problems isssues: https://moderndive.com/C-appendixC.html#data-wrangling

* https://leanpub.com/markua/

* https://education.rstudio.com/blog/2021/02/cbds/

* Start using "When comparing" everywhere.

* Fix tools to include discussion of Git for Windows and setting up the Terminal correctly: https://happygitwithr.com/shell.html#windows-shell-hell.

* Split maps into census and maps. Combine with ipums. Add code for making ipums graphics.

* Every model should feature a plot of predicted values and true outcomes. The decomposition is fine as far as it goes, but it is not the key image.

* Think harder about p() and Prob(). Which goes where?

* Use fitted() or predict() or both?

* Need testing in each chapter.

* Find/remove all usage of "controlling for x, we see". Use "adjust" instead.

* What do we think about the width of the code in the book? Sure seems like the comment lines go on for too long. Maybe? I don't like the way they care cut off in my Ipad, but . . . do many students read on Ipads?

* https://xkcd.com/2048/

* Show the secret weapon of doing the same regression many times and then gathering the results. nest_by(), perhaps.

* Better automated grading? https://ubc-dsci.github.io/rudaux

* Discuss the meaning of sigma more often. Really only need one sentence, but should give that sentence almost every time.

* Include links to disputes about governors work:

https://erikgahner.dk/2020/a-response-to-andrew-gelman/
https://statmodeling.stat.columbia.edu/2020/07/02/no-i-dont-believe-that-claim-based-on-regression-discontinuity-analysis-that/
https://github.com/jonspring/discontinuity/blob/master/fileb23c55435f90.gif

* Greek letters are for parameters which we can never observe. Latin letters are for observables.



* First, we can just print it. Chapter 7 walks the reader through all the parts of a stan_glm() model in detail. Later chapters will also show the printed model, but can move more quickly. Second, we create a summary table of the model using **gtsummary**. Note that this is just a different view of the same model. We don't show some things --- like sigma --- that we did show when just printing. We do show other things, like the 95% confidence interval which we did not show before. Neither is better! We use the one which is most helpful to our audience. Third, we use **tidybayes** to show histograms of the posterior distributions. The posterior is the underlying reality, the closest to the "truth" which we are going to get. The printed and table outputs are just summaries of the posterior. We might not show all three things every time, but we certainly always show the posterior. Graphics are pretty!

* After noting this formula, each example should create a plot with three histograms in a row --- left-to-right, the outcome (i.e., a histogram or density of Y), the fitted values (which is sometimes a spike, sometimes two spikes and so on) and, finally, the residuals. This highlights how we have *decomposed* the outcome into two parts: the model and the unmodeled variation. This belongs in the Courage chapter because it is a way of understanding the model we have made.

* We need a "machine" which generates these predictions, which is the same thing as a machine which fills in all the question marks in the Actual Preceptor Table, which is the same thing as a machine which produces "fake data" which looks a lot like our actual data.


* This also leads directly to the concept of *posterior predictive checks*, which is just fancy terminology for helping to see if your model makes sense. If your model is reasonable, then you would expect to see Z (a feature of the real data) in either new data or in fake data generated by your model. If you see Z, then you should have more faith in your model. If you don't, then something is wrong.

## To Discuss Later


* I like the hack of making your Rmd an index.Rmd and then the html will appear as a Github pages for free.


* Should use summary(fit_1) and discuss at some point. But when? Maybe Chapter 10?

* Do we need a cool graphics appendix, with  brief descriptions, pretty pictures from cool packages like: ggrepel, gghighlights, plotly. Others?



* More discussion of what it means to "control for" something in a regression. Right now, we don't mention this until chapter 11. Needs to be covered earlier, especially in chapter 9. That sets the stage for later.

* Standardize notation. What are predicted/fitted values? Use y_i everywhere, instead of using problem specific terms? That seems a bad (good?!) idea.

* Generate some error messages and then show that they can teach you something. Object does not exist. filter only have one equal sign, and so on. Do this all the time. Normalize the generation and processing of error messages.



*  Better workflow, automatic (with click confirmation) replacement of docs/ after successful check. Two parts: First, change the check so that it builds the book nicely. (Maybe not necessary. Maybe building the book in junk/ is OK?) Second, move the newly created book --- once it is accepted --- to docs/ on the master branch. Should we be taking multiple branches more seriously. Probably.
  + Things to discuss:
    - This change will prevent authors from easily knitting individual chapters. I will explore alternatives.
    - Two ways of handing auto-building and auot-updating:
      - 1) Create a new development branch. Students will submit PR to that branch. When you are ready, you can send a PR to merge to the master
           branch. The changes will only be live when you merge the development branch to the master branch.
      - 2) Keep things as they are. Once a student submits a PR, the build will directly go into docs/ and if successful, you can accept the PR
           and the new changes to the book will immediately be live. If the build check fails, do not accept the PR or else the deployment might
           break.


* Can you rebuild just a single chapter and then commit/push it? Right now, I have to rebuild the whole thing each time I want to make a single change. Takes too long.



## Other Items


Prediction checks.


# Appendices

Appendices have information that either a) a prof might reasonably decide not to assign or b) often contain material that students already know.

* Why Bayes?

* Messed up research articles. We need to prepare case studies of messed up articles. Start with those that Gelman cites. The tricky part is trying to figure out how to include these in class. And during which week do we use them.


* All the math you don't need to know. Bayes Theorem. Formulas. Normal distribution. Central limit theorem

* Advanced graphics, especially a tour of cool packages, including ggplotly and leaflet. gghighlight. ggstream.

* List of cool packages, googlesheet4 examples. : https://datavizm20.classes.andrewheiss.com/example/10-example/

* How to make an Rpubs and gists and saveWidgets:
https://datavizm20.classes.andrewheiss.com/example/10-example/

* Tufte and other graphics luminaries

* Leamer and other famous articles

* rtweet

* Making memes. Someone should figure out which meme maker is best for R. Or maybe we make our own. And then we make lots of memes for the book!


# From the Bookdown book

preview_chapter() and serve_book() as an aid to chapter writers.

webshot() tool for including images taken from webpages. Everytime we mention how cool source X is, we should provide a webshot of it. (And we should test that it exists.) Make the productivity chapter include way less of our prose.


p. 64 notes that adding the suffix 2 to various output formats gives you all the cool stuff, like figure captioning and numbering.

p. 74 has a useful discussion of configuration options for the _bookdown.yml file.

* rmd_subdir are subdirectories to search for source Rmd files. That seems critical for my submodule structure.

* output_dir is the output directory of the process (_book by default).

* clean is vector of files and directories to be cleaned by the clean_book() function.

pp. 5-6 discuss rmd_files as the way to define your own ordering for output files. This also goes in the _bookdown.yml file.



## Next Summer




* Other links of interest:

https://r-charts.com/ (use these tutorials)
https://www.youtube.com/watch?v=CQS4xxz-2s4 (marginal and conditional distributions; quite hard; maybe optional?)


* Books

https://rstudio4edu.github.io/rstudio4edu-book/
https://ubc-dsci.github.io/introduction-to-datascience/
https://monika76five.github.io/ProbBayes/
https://bookdown.org/roback/bookdown-BeyondMLR/
https://dtkaplan.github.io/DataComputingEbook/

* Courses

https://ubc-dsci.github.io/dsci-100/
https://dataviz-2021.netlify.app/
https://jmbuhr.de/dataIntro20/
https://athanasiamo.github.io/tidyquintro/

* Other

https://evamaerey.github.io/flipbooks/about (use flipbooks for classroom exercises?)
https://nickch-k.github.io/EconometricsSlides/
https://holtzy.github.io/Pimp-my-rmd/

 https://fromthebottomoftheheap.net/2020/04/30/rendering-your-readme-with-github-actions/
 https://github.com/itsyaoyu/github_actions/blob/master/.github/workflows/main.yml
 https://www.willandskill.se/en/deleting-your-git-commit-history-without-removing-repo-on-github-bitbucket/

https://mdbeckman.github.io/JSM2020-Virtual/

* More cartoons like [xkcd](https://cran.r-project.org/package=RXKCD)

styler package

https://storywrangling.org/

https://desiree.rbind.io/post/2019/making-tip-boxes-with-bookdown-and-rmarkdown/ for making pretty boxes in the book

https://github.com/wikimedia/waxer for Wikipedia data

http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/

https://github.com/agmath/AppliedStatsInteractive

https://github.com/moodymudskipper/flow

https://github.com/ucbds-infra/ottr-sample

https://github.com/allisonhorst/stats-illustrations

https://bookdown.org/yihui/rmarkdown-cookbook/equatiomatic.html

Consider Netifly: https://cerebralmastication.com/2019/05/11/publishing-bookdown-to-netlify-automagically/

https://kieranhealy.org/categories/visualization/

https://openintro-ims.netlify.app/

https://education.rstudio.com/blog/2020/07/gtsummary/
https://moderndive.github.io/moderndive_labs/index.html
https://education.rstudio.com/blog/2020/07/learning-learnr/
https://rmarkdown.rstudio.com/authoring_shiny_prerendered.HTML

https://rstudio-education.github.io/tidyverse-cookbook/. I love this image: https://twitter.com/icymi_r/status/1407199200627113989/photo/1



* Look at the **flair** package to format the code. Or does that require us to have two copies of code: working copy and colored copy? https://education.rstudio.com/blog/2020/05/flair/

* Does using **flipbookr** make sense in the middle of a chapter?

* https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.


Take a look at drat.











